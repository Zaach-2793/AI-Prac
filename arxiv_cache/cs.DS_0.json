"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\n  <link href=\"http://arxiv.org/api/query?search_query%3Dcat%3Acs.DS%26id_list%3D%26start%3D0%26max_results%3D50\" rel=\"self\" type=\"application/atom+xml\"/>\n  <title type=\"html\">ArXiv Query: search_query=cat:cs.DS&amp;id_list=&amp;start=0&amp;max_results=50</title>\n  <id>http://arxiv.org/api/Ne5SHylI2OKiKFMSXCeHcIn0xWY</id>\n  <updated>2025-03-22T00:00:00-04:00</updated>\n  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">25748</opensearch:totalResults>\n  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\n  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">50</opensearch:itemsPerPage>\n  <entry>\n    <id>http://arxiv.org/abs/cs/9301115v1</id>\n    <updated>1991-12-01T00:00:00Z</updated>\n    <published>1991-12-01T00:00:00Z</published>\n    <title>Context-free multilanguages</title>\n    <summary>  This article is a sketch of ideas that were once intended to appear in the\nauthor's famous series, \"The Art of Computer Programming\". He generalizes the\nnotion of a context-free language from a set to a multiset of words over an\nalphabet. The idea is to keep track of the number of ways to parse a string.\nFor example, \"fruit flies like a banana\" can famously be parsed in two ways;\nanalogous examples in the setting of programming languages may yet be important\nin the future.\n  The treatment is informal but essentially rigorous.\n</summary>\n    <author>\n      <name>Donald E. Knuth</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Abstract added by Greg Kuperberg</arxiv:comment>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Theoretical Studies in Computer Science, Ginsburg Festschrift</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/9301115v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/9301115v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/9608105v1</id>\n    <updated>1996-08-22T00:00:00Z</updated>\n    <published>1996-08-22T00:00:00Z</published>\n    <title>Shellsort with three increments</title>\n    <summary>  A perturbation technique can be used to simplify and sharpen A. C. Yao's\ntheorems about the behavior of shellsort with increments $(h,g,1)$. In\nparticular, when $h=\\Theta(n^{7/15})$ and $g=\\Theta(h^{1/5})$, the average\nrunning time is $O(n^{23/15})$. The proof involves interesting properties of\nthe inversions in random permutations that have been $h$-sorted and $g$-sorted.\n</summary>\n    <author>\n      <name>Svante Janson</name>\n    </author>\n    <author>\n      <name>Donald E. Knuth</name>\n    </author>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Random Structures Algorithms 10 (1997), no. 1-2, 125--142</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/9608105v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/9608105v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/9801103v1</id>\n    <updated>1998-01-15T00:00:00Z</updated>\n    <published>1998-01-15T00:00:00Z</published>\n    <title>Linear probing and graphs</title>\n    <summary>  Mallows and Riordan showed in 1968 that labeled trees with a small number of\ninversions are related to labeled graphs that are connected and sparse. Wright\nenumerated sparse connected graphs in 1977, and Kreweras related the inversions\nof trees to the so-called ``parking problem'' in 1980. A~combination of these\nthree results leads to a surprisingly simple analysis of the behavior of\nhashing by linear probing, including higher moments of the cost of successful\nsearch.\n</summary>\n    <author>\n      <name>Donald E. Knuth</name>\n    </author>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Algorithmica 22 (1998), no. 4, 561--568</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/9801103v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/9801103v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/9809012v1</id>\n    <updated>1998-09-09T02:38:56Z</updated>\n    <published>1998-09-09T02:38:56Z</published>\n    <title>A Fully Polynomial Randomized Approximation Scheme for the All Terminal\n  Network Reliability Problem</title>\n    <summary>  The classic all-terminal network reliability problem posits a graph, each of\nwhose edges fails independently with some given probability.\n</summary>\n    <author>\n      <name>David R. Karger</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">To appear in SICOMP</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/9809012v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/9809012v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2; G.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/9812007v1</id>\n    <updated>1998-12-08T21:29:20Z</updated>\n    <published>1998-12-08T21:29:20Z</published>\n    <title>Minimum Cuts in Near-Linear Time</title>\n    <summary>  We significantly improve known time bounds for solving the minimum cut\nproblem on undirected graphs. We use a ``semi-duality'' between minimum cuts\nand maximum spanning tree packings combined with our previously developed\nrandom sampling techniques. We give a randomized algorithm that finds a minimum\ncut in an m-edge, n-vertex graph with high probability in O(m log^3 n) time. We\nalso give a simpler randomized algorithm that finds all minimum cuts with high\nprobability in O(n^2 log n) time. This variant has an optimal RNC\nparallelization. Both variants improve on the previous best time bound of O(n^2\nlog^3 n). Other applications of the tree-packing approach are new, nearly tight\nbounds on the number of near minimum cuts a graph may have and a new data\nstructure for representing them in a space-efficient manner.\n</summary>\n    <author>\n      <name>David R. Karger</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/cs/9812007v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/9812007v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2;G.2.2;G.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/9812008v1</id>\n    <updated>1998-12-08T22:03:36Z</updated>\n    <published>1998-12-08T22:03:36Z</published>\n    <title>Approximate Graph Coloring by Semidefinite Programming</title>\n    <summary>  We consider the problem of coloring k-colorable graphs with the fewest\npossible colors. We present a randomized polynomial time algorithm that colors\na 3-colorable graph on $n$ vertices with min O(Delta^{1/3} log^{1/2} Delta log\nn), O(n^{1/4} log^{1/2} n) colors where Delta is the maximum degree of any\nvertex. Besides giving the best known approximation ratio in terms of n, this\nmarks the first non-trivial approximation result as a function of the maximum\ndegree Delta. This result can be generalized to k-colorable graphs to obtain a\ncoloring using min O(Delta^{1-2/k} log^{1/2} Delta log n), O(n^{1-3/(k+1)}\nlog^{1/2} n) colors. Our results are inspired by the recent work of Goemans and\nWilliamson who used an algorithm for semidefinite optimization problems, which\ngeneralize linear programs, to obtain improved approximations for the MAX CUT\nand MAX 2-SAT problems. An intriguing outcome of our work is a duality\nrelationship established between the value of the optimum solution to our\nsemidefinite program and the Lovasz theta-function. We show lower bounds on the\ngap between the optimum solution of our semidefinite program and the actual\nchromatic number; by duality this also demonstrates interesting new facts about\nthe theta-function.\n</summary>\n    <author>\n      <name>David Karger</name>\n    </author>\n    <author>\n      <name>Rajeev Motwani</name>\n    </author>\n    <author>\n      <name>Madhu Sudan</name>\n    </author>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">JACM 45(2), mar. 1998, pp.246--265</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/9812008v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/9812008v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2;G.2.2;G.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/9903010v1</id>\n    <updated>1999-03-11T19:36:05Z</updated>\n    <published>1999-03-11T19:36:05Z</published>\n    <title>A class of problems of NP to be worth to search an efficient solving\n  algorithm</title>\n    <summary>  We examine possibility to design an efficient solving algorithm for problems\nof the class \\np. It is introduced a classification of \\np problems by the\nproperty that a partial solution of size $k$ can be extended into a partial\nsolution of size $k+1$ in polynomial time. It is defined an unique class\nproblems to be worth to search an efficient solving algorithm. The problems,\nwhich are outside of this class, are inherently exponential. We show that the\nHamiltonian cycle problem is inherently exponential.\n</summary>\n    <author>\n      <name>Anatoly D. Plotnikov</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Vinnitsa Institute of Regional Economics and Management</arxiv:affiliation>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">9 pages, 1 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/9903010v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/9903010v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2;G.2.1;G.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/9906021v1</id>\n    <updated>1999-06-22T09:56:53Z</updated>\n    <published>1999-06-22T09:56:53Z</published>\n    <title>Reconstructing hv-Convex Polyominoes from Orthogonal Projections</title>\n    <summary>  Tomography is the area of reconstructing objects from projections. Here we\nwish to reconstruct a set of cells in a two dimensional grid, given the number\nof cells in every row and column. The set is required to be an hv-convex\npolyomino, that is all its cells must be connected and the cells in every row\nand column must be consecutive. A simple, polynomial algorithm for\nreconstructing hv-convex polyominoes is provided, which is several orders of\nmagnitudes faster than the best previously known algorithm from Barcucci et al.\nIn addition, the problem of reconstructing a special class of centered\nhv-convex polyominoes is addressed. (An object is centered if it contains a row\nwhose length equals the total width of the object). It is shown that in this\ncase the reconstruction problem can be solved in linear time.\n</summary>\n    <author>\n      <name>Christoph Durr</name>\n    </author>\n    <author>\n      <name>Marek Chrobak</name>\n    </author>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Information Processing Letters, 69, 1999, 283-289</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/9906021v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/9906021v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2; G.2.1\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/9911003v1</id>\n    <updated>1999-11-09T18:58:58Z</updated>\n    <published>1999-11-09T18:58:58Z</published>\n    <title>Subgraph Isomorphism in Planar Graphs and Related Problems</title>\n    <summary>  We solve the subgraph isomorphism problem in planar graphs in linear time,\nfor any pattern of constant size. Our results are based on a technique of\npartitioning the planar graph into pieces of small tree-width, and applying\ndynamic programming within each piece. The same methods can be used to solve\nother planar graph problems including connectivity, diameter, girth, induced\nsubgraph isomorphism, and shortest paths.\n</summary>\n    <author>\n      <name>David Eppstein</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">27 pages, 6 figures. A preliminary version of this paper appeared at\n  the 6th ACM-SIAM Symp. Discrete Algorithms, 1995</arxiv:comment>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">J. Graph Algorithms &amp; Applications 3(3):1-27, 1999</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/9911003v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/9911003v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/9912014v1</id>\n    <updated>1999-12-22T01:42:51Z</updated>\n    <published>1999-12-22T01:42:51Z</published>\n    <title>Fast Hierarchical Clustering and Other Applications of Dynamic Closest\n  Pairs</title>\n    <summary>  We develop data structures for dynamic closest pair problems with arbitrary\ndistance functions, that do not necessarily come from any geometric structure\non the objects. Based on a technique previously used by the author for\nEuclidean closest pairs, we show how to insert and delete objects from an\nn-object set, maintaining the closest pair, in O(n log^2 n) time per update and\nO(n) space. With quadratic space, we can instead use a quadtree-like structure\nto achieve an optimal time bound, O(n) per update. We apply these data\nstructures to hierarchical clustering, greedy matching, and TSP heuristics, and\ndiscuss other potential applications in machine learning, Groebner bases, and\nlocal improvement algorithms for partition and placement problems. Experiments\nshow our new methods to be faster in practice than previously used heuristics.\n</summary>\n    <author>\n      <name>David Eppstein</name>\n    </author>\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1145/351827.351829</arxiv:doi>\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1145/351827.351829\" rel=\"related\"/>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">20 pages, 9 figures. A preliminary version of this paper appeared at\n  the 9th ACM-SIAM Symp. on Discrete Algorithms, San Francisco, 1998, pp.\n  619-628. For source code and experimental results, see\n  http://www.ics.uci.edu/~eppstein/projects/pairs/</arxiv:comment>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">J. Experimental Algorithmics 5(1):1-23, 2000</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/9912014v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/9912014v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/9912020v2</id>\n    <updated>2002-05-24T09:40:47Z</updated>\n    <published>1999-12-30T07:50:11Z</published>\n    <title>Additive models in high dimensions</title>\n    <summary>  We discuss some aspects of approximating functions on high-dimensional data\nsets with additive functions or ANOVA decompositions, that is, sums of\nfunctions depending on fewer variables each. It is seen that under appropriate\nsmoothness conditions, the errors of the ANOVA decompositions are of order\n$O(n^{m/2})$ for approximations using sums of functions of up to $m$ variables\nunder some mild restrictions on the (possibly dependent) predictor variables.\nSeveral simulated examples illustrate this behaviour.\n</summary>\n    <author>\n      <name>Markus Hegland</name>\n    </author>\n    <author>\n      <name>Vladimir Pestov</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">LaTeX 2e document, 21 pages, 5 figures</arxiv:comment>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Proc. of 12th Computational Techniques and Applications\n  Conference, CTAC-2004 (Rob May and A.J. Roberts, eds.), ANZIAM J. 46 (2005),\n  C1205-C1221.</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/9912020v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/9912020v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.8\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0003078v1</id>\n    <updated>2000-03-24T23:31:24Z</updated>\n    <published>2000-03-24T23:31:24Z</published>\n    <title>About the finding of independent vertices of a graph</title>\n    <summary>  We examine the Maximum Independent Set Problem in an undirected graph. The\nmain result is that this problem can be considered as the solving the same\nproblem in a subclass of the weighted normal twin-orthogonal graphs. The\nproblem is formulated which is dual to the problem above. It is shown that, for\ntrivial twin-orthogonal graphs, any of its maximal independent set is also\nmaximum one.\n</summary>\n    <author>\n      <name>Anatoly D. Plotnikov</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">8 pages, 2 figures</arxiv:comment>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">About the finding of independent vertices of a graph, Journal\n  \"Kibernetika\", No. 1, 1989, p. 119 - 121</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/0003078v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0003078v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2;G.2.1;G.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0006046v1</id>\n    <updated>2000-06-30T22:04:04Z</updated>\n    <published>2000-06-30T22:04:04Z</published>\n    <title>3-Coloring in Time O(1.3289^n)</title>\n    <summary>  We consider worst case time bounds for NP-complete problems including 3-SAT,\n3-coloring, 3-edge-coloring, and 3-list-coloring. Our algorithms are based on a\nconstraint satisfaction (CSP) formulation of these problems. 3-SAT is\nequivalent to (2,3)-CSP while the other problems above are special cases of\n(3,2)-CSP; there is also a natural duality transformation from (a,b)-CSP to\n(b,a)-CSP. We give a fast algorithm for (3,2)-CSP and use it to improve the\ntime bounds for solving the other problems listed above. Our techniques involve\na mixture of Davis-Putnam-style backtracking with more sophisticated matching\nand network flow based ideas.\n</summary>\n    <author>\n      <name>Richard Beigel</name>\n    </author>\n    <author>\n      <name>David Eppstein</name>\n    </author>\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1016/j.jalgor.2004.06.008</arxiv:doi>\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1016/j.jalgor.2004.06.008\" rel=\"related\"/>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">31 pages, 22 figures. An earlier version of this paper was presented\n  at the 36th IEEE Symp. Foundations of Comp. Sci., 1995, and appears as ECCC\n  TR 95-033</arxiv:comment>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">J. Algorithms 54:2 (2005) 168-204</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/0006046v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0006046v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0007029v1</id>\n    <updated>2000-07-18T21:50:04Z</updated>\n    <published>2000-07-18T21:50:04Z</published>\n    <title>Dimension-Dependent behavior in the satisfability of random k-Horn\n  formulae</title>\n    <summary>  We determine the asymptotical satisfiability probability of a random\nat-most-k-Horn formula, via a probabilistic analysis of a simple version,\ncalled PUR, of positive unit resolution. We show that for k=k(n)-&gt;oo the\nproblem can be ``reduced'' to the case k(n)=n, that was solved in\ncs.DS/9912001. On the other hand, in the case k= a constant the behavior of PUR\nis modeled by a simple queuing chain, leading to a closed-form solution when\nk=2. Our analysis predicts an ``easy-hard-easy'' pattern in this latter case.\nUnder a rescaled parameter, the graphs of satisfaction probability\ncorresponding to finite values of k converge to the one for the uniform case, a\n``dimension-dependent behavior'' similar to the one found experimentally by\nKirkpatrick and Selman (Science'94) for k-SAT. The phenomenon is qualitatively\nexplained by a threshold property for the number of iterations of PUR makes on\nrandom satisfiable Horn formulas.\n</summary>\n    <author>\n      <name>Gabriel Istrate</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/cs/0007029v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0007029v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0007043v1</id>\n    <updated>2000-07-31T00:13:17Z</updated>\n    <published>2000-07-31T00:13:17Z</published>\n    <title>Min-Max Fine Heaps</title>\n    <summary>  In this paper we present a new data structure for double ended priority\nqueue, called min-max fine heap, which combines the techniques used in fine\nheap and traditional min-max heap. The standard operations on this proposed\nstructure are also presented, and their analysis indicates that the new\nstructure outperforms the traditional one.\n</summary>\n    <author>\n      <name>Suman Kumar Nath</name>\n    </author>\n    <author>\n      <name>Rezaul Alam Chowdhury</name>\n    </author>\n    <author>\n      <name>M. Kaykobad</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">6 pages, pdf file</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0007043v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0007043v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"E.1\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0008011v1</id>\n    <updated>2000-08-16T20:39:45Z</updated>\n    <published>2000-08-16T20:39:45Z</published>\n    <title>All Pairs Shortest Paths using Bridging Sets and Rectangular Matrix\n  Multiplication</title>\n    <summary>  We present two new algorithms for solving the {\\em All Pairs Shortest Paths}\n(APSP) problem for weighted directed graphs. Both algorithms use fast matrix\nmultiplication algorithms.\n  The first algorithm solves the APSP problem for weighted directed graphs in\nwhich the edge weights are integers of small absolute value in $\\Ot(n^{2+\\mu})$\ntime, where $\\mu$ satisfies the equation $\\omega(1,\\mu,1)=1+2\\mu$ and\n$\\omega(1,\\mu,1)$ is the exponent of the multiplication of an $n\\times n^\\mu$\nmatrix by an $n^\\mu \\times n$ matrix. Currently, the best available bounds on\n$\\omega(1,\\mu,1)$, obtained by Coppersmith, imply that $\\mu&lt;0.575$. The running\ntime of our algorithm is therefore $O(n^{2.575})$. Our algorithm improves on\nthe $\\Ot(n^{(3+\\omega)/2})$ time algorithm, where $\\omega=\\omega(1,1,1)&lt;2.376$\nis the usual exponent of matrix multiplication, obtained by Alon, Galil and\nMargalit, whose running time is only known to be $O(n^{2.688})$.\n  The second algorithm solves the APSP problem {\\em almost} exactly for\ndirected graphs with {\\em arbitrary} non-negative real weights. The algorithm\nruns in $\\Ot((n^\\omega/\\eps)\\log (W/\\eps))$ time, where $\\eps&gt;0$ is an error\nparameter and W is the largest edge weight in the graph, after the edge weights\nare scaled so that the smallest non-zero edge weight in the graph is 1. It\nreturns estimates of all the distances in the graph with a stretch of at most\n$1+\\eps$. Corresponding paths can also be found efficiently.\n</summary>\n    <author>\n      <name>Uri Zwick</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">27 pages, 19 figures, a preliminary version appeared in FOCS'98 under\n  a slightly different title</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0008011v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0008011v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2;G.2.2;G.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0009006v1</id>\n    <updated>2000-09-13T20:42:55Z</updated>\n    <published>2000-09-13T20:42:55Z</published>\n    <title>Improved Algorithms for 3-Coloring, 3-Edge-Coloring, and Constraint\n  Satisfaction</title>\n    <summary>  We consider worst case time bounds for NP-complete problems including 3-SAT,\n3-coloring, 3-edge-coloring, and 3-list-coloring. Our algorithms are based on a\nconstraint satisfaction (CSP) formulation of these problems; 3-SAT is\nequivalent to (2,3)-CSP while the other problems above are special cases of\n(3,2)-CSP. We give a fast algorithm for (3,2)-CSP and use it to improve the\ntime bounds for solving the other problems listed above. Our techniques involve\na mixture of Davis-Putnam-style backtracking with more sophisticated matching\nand network flow based ideas.\n</summary>\n    <author>\n      <name>David Eppstein</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">11 pages, 7 figures. To appear in 12th ACM/SIAM Symp. Discrete\n  Algorithms (SODA 2001). This extended abstract summarizes results from\n  cs.DS/0006046 \"3-coloring in time O(1.3289^n)\" (with Richard Beigel) that\n  were found after our FOCS 1995 paper on the same subject</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0009006v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0009006v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0011047v1</id>\n    <updated>2000-11-15T00:00:00Z</updated>\n    <published>2000-11-15T00:00:00Z</published>\n    <title>Dancing links</title>\n    <summary>  The author presents two tricks to accelerate depth-first search algorithms\nfor a class of combinatorial puzzle problems, such as tiling a tray by a fixed\nset of polyominoes. The first trick is to implement each assumption of the\nsearch with reversible local operations on doubly linked lists. By this trick,\nevery step of the search affects the data incrementally.\n  The second trick is to add a ghost square that represents the identity of\neach polyomino. Thus puts the rule that each polyomino be used once on the same\nfooting as the rule that each square be covered once. The coding simplifies to\na more abstract form which is equivalent to 0-1 integer programming. More\nsignificantly for the total computation time, the search can naturally switch\nbetween placing a fixed polyomino or covering a fixed square at different\nstages, according to a combined heuristic.\n  Finally the author reports excellent performance for his algorithm for some\nfamiliar puzzles. These include tiling a hexagon by 19 hexiamonds and the N\nqueens problem for N up to 18.\n</summary>\n    <author>\n      <name>Donald E. Knuth</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Abstract added by Greg Kuperberg</arxiv:comment>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Millenial Perspectives in Computer Science, 2000, 187--214</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/0011047v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0011047v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0012002v1</id>\n    <updated>2000-12-02T17:47:26Z</updated>\n    <published>2000-12-02T17:47:26Z</published>\n    <title>Random Shuffling to Reduce Disorder in Adaptive Sorting Scheme</title>\n    <summary>  In this paper we present a random shuffling scheme to apply with adaptive\nsorting algorithms. Adaptive sorting algorithms utilize the presortedness\npresent in a given sequence. We have probabilistically increased the amount of\npresortedness present in a sequence by using a random shuffling technique that\nrequires little computation. Theoretical analysis suggests that the proposed\nscheme can improve the performance of adaptive sorting. Experimental results\nshow that it significantly reduces the amount of disorder present in a given\nsequence and improves the execution time of adaptive sorting algorithm as well.\n</summary>\n    <author>\n      <name>Md. Enamul Karim</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">University of Dhaka</arxiv:affiliation>\n    </author>\n    <author>\n      <name>Abdun Naser Mahmood</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">University of Dhaka</arxiv:affiliation>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">7 pages, 2 tables</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0012002v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0012002v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0111050v7</id>\n    <updated>2003-10-09T16:20:36Z</updated>\n    <published>2001-11-19T23:37:14Z</published>\n    <title>Smoothed Analysis of Algorithms: Why the Simplex Algorithm Usually Takes\n  Polynomial Time</title>\n    <summary>  We introduce the smoothed analysis of algorithms, which is a hybrid of the\nworst-case and average-case analysis of algorithms. In smoothed analysis, we\nmeasure the maximum over inputs of the expected performance of an algorithm\nunder small random perturbations of that input. We measure this performance in\nterms of both the input size and the magnitude of the perturbations. We show\nthat the simplex algorithm has polynomial smoothed complexity.\n</summary>\n    <author>\n      <name>Daniel A. Spielman</name>\n    </author>\n    <author>\n      <name>Shang-Hua Teng</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Revised. Improved statement of main theorem</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0111050v7\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0111050v7\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"G.1.6\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0112022v2</id>\n    <updated>2001-12-25T21:29:22Z</updated>\n    <published>2001-12-21T05:58:12Z</published>\n    <title>Faster Algorithm of String Comparison</title>\n    <summary>  In many applications, it is necessary to determine the string similarity.\nEdit distance[WF74] approach is a classic method to determine Field Similarity.\nA well known dynamic programming algorithm [GUS97] is used to calculate edit\ndistance with the time complexity O(nm). (for worst case, average case and even\nbest case) Instead of continuing with improving the edit distance approach,\n[LL+99] adopted a brand new approach-token-based approach. Its new concept of\ntoken-base-retain the original semantic information, good time complex-O(nm)\n(for worst, average and best case) and good experimental performance make it a\nmilestone paper in this area. Further study indicates that there is still room\nfor improvement of its Field Similarity algorithm. Our paper is to introduce a\npackage of substring-based new algorithms to determine Field Similarity.\nCombined together, our new algorithms not only achieve higher accuracy but also\ngain the time complexity O(knm) (k&lt;0.75) for worst case, O(*n) where &lt;6 for\naverage case and O(1) for best case. Throughout the paper, we use the approach\nof comparative examples to show higher accuracy of our algorithms compared to\nthe one proposed in [LL+99]. Theoretical analysis, concrete examples and\nexperimental result show that our algorithms can significantly improve the\naccuracy and time complexity of the calculation of Field Similarity. [US97] D.\nGuseld. Algorithms on Strings, Trees and Sequences, in Computer Science and\nComputational Biology. [LL+99] Mong Li Lee, Cleansing data for mining and\nwarehousing, In Proceedings of the 10th International Conference on Database\nand Expert Systems Applications (DEXA99), pages 751-760,August 1999. [WF74] R.\nWagner and M. Fisher, The String to String Correction Problem, JACM 21 pages\n168-173, 1974.\n</summary>\n    <author>\n      <name>Qi Xiao Yang</name>\n    </author>\n    <author>\n      <name>Sung Sam Yuan</name>\n    </author>\n    <author>\n      <name>Lu Chun</name>\n    </author>\n    <author>\n      <name>Li Zhao</name>\n    </author>\n    <author>\n      <name>Sun Peng</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/cs/0112022v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0112022v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"I.1.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0203018v1</id>\n    <updated>2002-03-13T19:09:41Z</updated>\n    <published>2002-03-13T19:09:41Z</published>\n    <title>Improving Table Compression with Combinatorial Optimization</title>\n    <summary>  We study the problem of compressing massive tables within the\npartition-training paradigm introduced by Buchsbaum et al. [SODA'00], in which\na table is partitioned by an off-line training procedure into disjoint\nintervals of columns, each of which is compressed separately by a standard,\non-line compressor like gzip. We provide a new theory that unifies previous\nexperimental observations on partitioning and heuristic observations on column\npermutation, all of which are used to improve compression rates. Based on the\ntheory, we devise the first on-line training algorithms for table compression,\nwhich can be applied to individual files, not just continuously operating\nsources; and also a new, off-line training algorithm, based on a link to the\nasymmetric traveling salesman problem, which improves on prior work by\nrearranging columns prior to partitioning. We demonstrate these results\nexperimentally. On various test files, the on-line algorithms provide 35-55%\nimprovement over gzip with negligible slowdown; the off-line reordering\nprovides up to 20% further improvement over partitioning alone. We also show\nthat a variation of the table compression problem is MAX-SNP hard.\n</summary>\n    <author>\n      <name>Adam L. Buchsbaum</name>\n    </author>\n    <author>\n      <name>Glenn S. Fowler</name>\n    </author>\n    <author>\n      <name>Raffaele Giancarlo</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">22 pages, 2 figures, 5 tables, 23 references. Extended abstract\n  appears in Proc. 13th ACM-SIAM SODA, pp. 213-222, 2002</arxiv:comment>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">JACM 50(6):825-851, 2003</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/0203018v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0203018v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"E.4; F.1.3; F.2.2; G.2.1; H.1.1; H.1.8; H.2.7\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0204033v1</id>\n    <updated>2002-04-15T04:48:21Z</updated>\n    <published>2002-04-15T04:48:21Z</published>\n    <title>Randomized selection revisited</title>\n    <summary>  We show that several versions of Floyd and Rivest's algorithm Select for\nfinding the $k$th smallest of $n$ elements require at most\n$n+\\min\\{k,n-k\\}+o(n)$ comparisons on average and with high probability. This\nrectifies the analysis of Floyd and Rivest, and extends it to the case of\nnondistinct elements. Our computational results confirm that Select may be the\nbest algorithm in practice.\n</summary>\n    <author>\n      <name>Krzysztof C. Kiwiel</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">25 pages, LaTeX 2e</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0204033v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0204033v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2;G3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0205029v1</id>\n    <updated>2002-05-17T23:52:11Z</updated>\n    <published>2002-05-17T23:52:11Z</published>\n    <title>A Codebook Generation Algorithm for Document Image Compression</title>\n    <summary>  Pattern-matching-based document-compression systems (e.g. for faxing) rely on\nfinding a small set of patterns that can be used to represent all of the ink in\nthe document. Finding an optimal set of patterns is NP-hard; previous\ncompression schemes have resorted to heuristics. This paper describes an\nextension of the cross-entropy approach, used previously for measuring pattern\nsimilarity, to this problem. This approach reduces the problem to a k-medians\nproblem, for which the paper gives a new algorithm with a provably good\nperformance guarantee. In comparison to previous heuristics (First Fit, with\nand without generalized Lloyd's/k-means postprocessing steps), the new\nalgorithm generates a better codebook, resulting in an overall improvement in\ncompression performance of almost 17%.\n</summary>\n    <author>\n      <name>Qin Zhang</name>\n    </author>\n    <author>\n      <name>John Danskin</name>\n    </author>\n    <author>\n      <name>Neal Young</name>\n    </author>\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1109/DCC.1997.582053</arxiv:doi>\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1109/DCC.1997.582053\" rel=\"related\"/>\n    <link href=\"http://arxiv.org/abs/cs/0205029v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0205029v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.0, E.4, I.4.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0205039v1</id>\n    <updated>2002-05-18T15:12:41Z</updated>\n    <published>2002-05-18T15:12:41Z</published>\n    <title>Sequential and Parallel Algorithms for Mixed Packing and Covering</title>\n    <summary>  Mixed packing and covering problems are problems that can be formulated as\nlinear programs using only non-negative coefficients. Examples include\nmulticommodity network flow, the Held-Karp lower bound on TSP, fractional\nrelaxations of set cover, bin-packing, knapsack, scheduling problems,\nminimum-weight triangulation, etc. This paper gives approximation algorithms\nfor the general class of problems. The sequential algorithm is a simple greedy\nalgorithm that can be implemented to find an epsilon-approximate solution in\nO(epsilon^-2 log m) linear-time iterations. The parallel algorithm does\ncomparable work but finishes in polylogarithmic time.\n  The results generalize previous work on pure packing and covering (the\nspecial case when the constraints are all \"less-than\" or all \"greater-than\") by\nMichael Luby and Noam Nisan (1993) and Naveen Garg and Jochen Konemann (1998).\n</summary>\n    <author>\n      <name>Neal E. Young</name>\n    </author>\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1109/SFCS.2001.959930</arxiv:doi>\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1109/SFCS.2001.959930\" rel=\"related\"/>\n    <link href=\"http://arxiv.org/abs/cs/0205039v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0205039v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.1, G.1.6\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0205048v2</id>\n    <updated>2012-04-23T19:50:06Z</updated>\n    <published>2002-05-18T18:57:04Z</published>\n    <title>Huffman Coding with Letter Costs: A Linear-Time Approximation Scheme</title>\n    <summary>  We give a polynomial-time approximation scheme for the generalization of\nHuffman Coding in which codeword letters have non-uniform costs (as in Morse\ncode, where the dash is twice as long as the dot). The algorithm computes a\n(1+epsilon)-approximate solution in time O(n + f(epsilon) log^3 n), where n is\nthe input size.\n</summary>\n    <author>\n      <name>Mordecai Golin</name>\n    </author>\n    <author>\n      <name>Claire Mathieu</name>\n    </author>\n    <author>\n      <name>Neal E. Young</name>\n    </author>\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1137/100794092</arxiv:doi>\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1137/100794092\" rel=\"related\"/>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">SIAM Journal on Computing 41(3):684-713(2012)</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/0205048v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0205048v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.0; E.4; I.4.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0205049v1</id>\n    <updated>2002-05-18T19:05:55Z</updated>\n    <published>2002-05-18T19:05:55Z</published>\n    <title>Prefix Codes: Equiprobable Words, Unequal Letter Costs</title>\n    <summary>  Describes a near-linear-time algorithm for a variant of Huffman coding, in\nwhich the letters may have non-uniform lengths (as in Morse code), but with the\nrestriction that each word to be encoded has equal probability. [See also\n``Huffman Coding with Unequal Letter Costs'' (2002).]\n</summary>\n    <author>\n      <name>Mordecai Golin</name>\n    </author>\n    <author>\n      <name>Neal E. Young</name>\n    </author>\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1137/S0097539794268388</arxiv:doi>\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1137/S0097539794268388\" rel=\"related\"/>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">proceedings version in ICALP (1994)</arxiv:comment>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">SIAM J. Computing 25(6):1281-1304 (1996)</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/0205049v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0205049v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.0; E.4; I.4.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0206033v1</id>\n    <updated>2002-06-24T06:50:52Z</updated>\n    <published>2002-06-24T06:50:52Z</published>\n    <title>Algorithms for Media</title>\n    <summary>  Falmagne recently introduced the concept of a medium, a combinatorial object\nencompassing hyperplane arrangements, topological orderings, acyclic\norientations, and many other familiar structures. We find efficient solutions\nfor several algorithmic problems on media: finding short reset sequences,\nshortest paths, testing whether a medium has a closed orientation, and listing\nthe states of a medium given a black-box description.\n</summary>\n    <author>\n      <name>David Eppstein</name>\n    </author>\n    <author>\n      <name>Jean-Claude Falmagne</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">12 pages</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0206033v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0206033v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0207061v2</id>\n    <updated>2006-11-14T19:15:37Z</updated>\n    <published>2002-07-15T18:47:57Z</published>\n    <title>Linear-Time Pointer-Machine Algorithms for Path-Evaluation Problems on\n  Trees and Graphs</title>\n    <summary>  We present algorithms that run in linear time on pointer machines for a\ncollection of problems, each of which either directly or indirectly requires\nthe evaluation of a function defined on paths in a tree. These problems\npreviously had linear-time algorithms but only for random-access machines\n(RAMs); the best pointer-machine algorithms were super-linear by an\ninverse-Ackermann-function factor. Our algorithms are also simpler, in some\ncases substantially, than the previous linear-time RAM algorithms. Our\nimprovements come primarily from three new ideas: a refined analysis of path\ncompression that gives a linear bound if the compressions favor certain nodes,\na pointer-based radix sort as a replacement for table-based methods, and a more\ncareful partitioning of a tree into easily managed parts. Our algorithms\ncompute nearest common ancestors off-line, verify and construct minimum\nspanning trees, do interval analysis on a flowgraph, find the dominators of a\nflowgraph, and build the component tree of a weighted tree.\n</summary>\n    <author>\n      <name>Adam L. Buchsbaum</name>\n    </author>\n    <author>\n      <name>Loukas Georgiadis</name>\n    </author>\n    <author>\n      <name>Haim Kaplan</name>\n    </author>\n    <author>\n      <name>Anne Rogers</name>\n    </author>\n    <author>\n      <name>Robert E. Tarjan</name>\n    </author>\n    <author>\n      <name>Jeffery R. Westbrook</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">41 pages; 10 figures; 1 table; 65 references. This work is partially\n  covered by the extended abstracts, ``Linear-Time Pointer-Machine Algorithms\n  for Least Common Ancestors, MST Verification, and Dominators,'' Proc. 30th\n  ACM Symp. on Theory of Computing, pp. 279-888, 1998, and ``Finding Dominators\n  Revisited,'' Proc. 15th ACM-SIAM Symp. on Discrete Algorithms, pp. 862-871,\n  2004</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0207061v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0207061v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"D.3.4; E.1; F.1.1; F.2.2; G.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0207066v1</id>\n    <updated>2002-07-16T17:58:48Z</updated>\n    <published>2002-07-16T17:58:48Z</published>\n    <title>Polynomial Time Data Reduction for Dominating Set</title>\n    <summary>  Dealing with the NP-complete Dominating Set problem on undirected graphs, we\ndemonstrate the power of data reduction by preprocessing from a theoretical as\nwell as a practical side. In particular, we prove that Dominating Set\nrestricted to planar graphs has a so-called problem kernel of linear size,\nachieved by two simple and easy to implement reduction rules. Moreover, having\nimplemented our reduction rules, first experiments indicate the impressive\npractical potential of these rules. Thus, this work seems to open up a new and\nprospective way how to cope with one of the most important problems in graph\ntheory and combinatorial optimization.\n</summary>\n    <author>\n      <name>Jochen Alber</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Universitaet Tuebingen Germany</arxiv:affiliation>\n    </author>\n    <author>\n      <name>Michael R. Fellows</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">University of Newcastle Australia</arxiv:affiliation>\n    </author>\n    <author>\n      <name>Rolf Niedermeier</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Universitaet Tuebingen Germany</arxiv:affiliation>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">25 pages, 4 figures (using 8 files), extended abstract entitled\n  \"Efficient Data Reduction for Dominating Set: A Linear Problem Kernel for the\n  Planar Case\" appeared in the Proceedings of the 8th SWAT 2002, LNCS 2368,\n  pages 150-159, Springer-Verlag, 2002</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0207066v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0207066v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2; G.2.1; G.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0207082v1</id>\n    <updated>2002-07-24T19:56:17Z</updated>\n    <published>2002-07-24T19:56:17Z</published>\n    <title>Dynamic Generators of Topologically Embedded Graphs</title>\n    <summary>  We provide a data structure for maintaining an embedding of a graph on a\nsurface (represented combinatorially by a permutation of edges around each\nvertex) and computing generators of the fundamental group of the surface, in\namortized time O(log n + log g(log log g)^3) per update on a surface of genus\ng; we can also test orientability of the surface in the same time, and maintain\nthe minimum and maximum spanning tree of the graph in time O(log n + log^4 g)\nper update. Our data structure allows edge insertion and deletion as well as\nthe dual operations; these operations may implicitly change the genus of the\nembedding surface. We apply similar ideas to improve the constant factor in a\nseparator theorem for low-genus graphs, and to find in linear time a\ntree-decomposition of low-genus low-diameter graphs.\n</summary>\n    <author>\n      <name>David Eppstein</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">13 pages, 2 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0207082v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0207082v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0209033v2</id>\n    <updated>2003-03-11T13:06:09Z</updated>\n    <published>2002-09-30T10:33:13Z</published>\n    <title>Preemptive Scheduling of Equal-Length Jobs to Maximize Weighted\n  Throughput</title>\n    <summary>  We study the problem of computing a preemptive schedule of equal-length jobs\nwith given release times, deadlines and weights. Our goal is to maximize the\nweighted throughput, which is the total weight of completed jobs. In Graham's\nnotation this problem is described as (1 | r_j;p_j=p;pmtn | sum w_j U_j). We\nprovide an O(n^4)-time algorithm for this problem, improving the previous bound\nof O(n^{10}) by Baptiste.\n</summary>\n    <author>\n      <name>Philippe Baptiste</name>\n    </author>\n    <author>\n      <name>Marek Chrobak</name>\n    </author>\n    <author>\n      <name>Christoph Durr</name>\n    </author>\n    <author>\n      <name>Wojciech Jawor</name>\n    </author>\n    <author>\n      <name>Nodari Vakhania</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">gained one author and lost one degree in the complexity</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0209033v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0209033v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0210006v2</id>\n    <updated>2003-06-20T18:25:13Z</updated>\n    <published>2002-10-09T04:49:56Z</published>\n    <title>Dynamic Ordered Sets with Exponential Search Trees</title>\n    <summary>  We introduce exponential search trees as a novel technique for converting\nstatic polynomial space search structures for ordered sets into fully-dynamic\nlinear space data structures.\n  This leads to an optimal bound of O(sqrt(log n/loglog n)) for searching and\nupdating a dynamic set of n integer keys in linear space. Here searching an\ninteger y means finding the maximum key in the set which is smaller than or\nequal to y. This problem is equivalent to the standard text book problem of\nmaintaining an ordered set (see, e.g., Cormen, Leiserson, Rivest, and Stein:\nIntroduction to Algorithms, 2nd ed., MIT Press, 2001).\n  The best previous deterministic linear space bound was O(log n/loglog n) due\nFredman and Willard from STOC 1990. No better deterministic search bound was\nknown using polynomial space.\n  We also get the following worst-case linear space trade-offs between the\nnumber n, the word length w, and the maximal key U &lt; 2^w: O(min{loglog n+log\nn/log w, (loglog n)(loglog U)/(logloglog U)}). These trade-offs are, however,\nnot likely to be optimal.\n  Our results are generalized to finger searching and string searching,\nproviding optimal results for both in terms of n.\n</summary>\n    <author>\n      <name>Arne Andersson</name>\n    </author>\n    <author>\n      <name>Mikkel Thorup</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Revision corrects some typoes and state things better for\n  applications in subsequent papers</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0210006v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0210006v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"E.1;F.2.2;G.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0210013v2</id>\n    <updated>2002-10-14T22:08:54Z</updated>\n    <published>2002-10-14T17:17:28Z</published>\n    <title>On the Sum-of-Squares Algorithm for Bin Packing</title>\n    <summary>  In this paper we present a theoretical analysis of the deterministic on-line\n{\\em Sum of Squares} algorithm ($SS$) for bin packing introduced and studied\nexperimentally in \\cite{CJK99}, along with several new variants. $SS$ is\napplicable to any instance of bin packing in which the bin capacity $B$ and\nitem sizes $s(a)$ are integral (or can be scaled to be so), and runs in time\n$O(nB)$. It performs remarkably well from an average case point of view: For\nany discrete distribution in which the optimal expected waste is sublinear,\n$SS$ also has sublinear expected waste. For any discrete distribution where the\noptimal expected waste is bounded, $SS$ has expected waste at most $O(\\log n)$.\nIn addition, we discuss several interesting variants on $SS$, including a\nrandomized $O(nB\\log B)$-time on-line algorithm $SS^*$, based on $SS$, whose\nexpected behavior is essentially optimal for all discrete distributions.\nAlgorithm $SS^*$ also depends on a new linear-programming-based\npseudopolynomial-time algorithm for solving the NP-hard problem of determining,\ngiven a discrete distribution $F$, just what is the growth rate for the optimal\nexpected waste. This article is a greatly expanded version of the conference\npaper \\cite{sumsq2000}.\n</summary>\n    <author>\n      <name>Janos Csirik</name>\n    </author>\n    <author>\n      <name>David S. Johnson</name>\n    </author>\n    <author>\n      <name>Claire Kenyon</name>\n    </author>\n    <author>\n      <name>James B. Orlin</name>\n    </author>\n    <author>\n      <name>Peter W. Shor</name>\n    </author>\n    <author>\n      <name>Richard R. Weber</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">72 pages</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0210013v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0210013v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2 G.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0211001v2</id>\n    <updated>2011-03-08T17:58:54Z</updated>\n    <published>2002-11-01T06:23:00Z</published>\n    <title>Fast and Simple Computation of All Longest Common Subsequences</title>\n    <summary>  This paper shows that a simple algorithm produces the {\\em\nall-prefixes-LCSs-graph} in $O(mn)$ time for two input sequences of size $m$\nand $n$. Given any prefix $p$ of the first input sequence and any prefix $q$ of\nthe second input sequence, all longest common subsequences (LCSs) of $p$ and\n$q$ can be generated in time proportional to the output size, once the\nall-prefixes-LCSs-graph has been constructed. The problem can be solved in the\ncontext of generating all the distinct character strings that represent an LCS\nor in the context of generating all ways of embedding an LCS in the two input\nstrings.\n</summary>\n    <author>\n      <name>Ronald I. Greenberg</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">LaTeX 8 pages, 4 figures, corrected typos (especially in pseudocode\n  in Figure 4)</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0211001v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0211001v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0211009v1</id>\n    <updated>2002-11-11T12:02:30Z</updated>\n    <published>2002-11-11T12:02:30Z</published>\n    <title>Improved Phylogeny Comparisons: Non-Shared Edges Nearest Neighbor\n  Interchanges, and Subtree Transfers</title>\n    <summary>  The number of the non-shared edges of two phylogenies is a basic measure of\nthe dissimilarity between the phylogenies. The non-shared edges are also the\nbuilding block for approximating a more sophisticated metric called the nearest\nneighbor interchange (NNI) distance. In this paper, we give the first\nsubquadratic-time algorithm for finding the non-shared edges, which are then\nused to speed up the existing approximating algorithm for the NNI distance from\n$O(n^2)$ time to $O(n \\log n)$ time. Another popular distance metric for\nphylogenies is the subtree transfer (STT) distance. Previous work on computing\nthe STT distance considered degree-3 trees only. We give an approximation\nalgorithm for the STT distance for degree-$d$ trees with arbitrary $d$ and with\ngeneralized STT operations.\n</summary>\n    <author>\n      <name>Wing-Kai Hon</name>\n    </author>\n    <author>\n      <name>Ming-Yang Kao</name>\n    </author>\n    <author>\n      <name>Tak-Wah Lam</name>\n    </author>\n    <author>\n      <name>Wing-Kin Sung</name>\n    </author>\n    <author>\n      <name>Siu-Ming Yiu</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/cs/0211009v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0211009v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0211010v2</id>\n    <updated>2004-07-28T21:03:35Z</updated>\n    <published>2002-11-12T03:32:02Z</published>\n    <title>Efficient Tree Layout in a Multilevel Memory Hierarchy</title>\n    <summary>  We consider the problem of laying out a tree with fixed parent/child\nstructure in hierarchical memory. The goal is to minimize the expected number\nof block transfers performed during a search along a root-to-leaf path, subject\nto a given probability distribution on the leaves. This problem was previously\nconsidered by Gil and Itai, who developed optimal but slow algorithms when the\nblock-transfer size B is known. We present faster but approximate algorithms\nfor the same problem; the fastest such algorithm runs in linear time and\nproduces a solution that is within an additive constant of optimal.\n  In addition, we show how to extend any approximately optimal algorithm to the\ncache-oblivious setting in which the block-transfer size is unknown to the\nalgorithm. The query performance of the cache-oblivious layout is within a\nconstant factor of the query performance of the optimal known-block-size\nlayout. Computing the cache-oblivious layout requires only logarithmically many\ncalls to the layout algorithm for known block size; in particular, the\ncache-oblivious layout can be computed in O(N lg N) time, where N is the number\nof nodes.\n  Finally, we analyze two greedy strategies, and show that they have a\nperformance ratio between Omega(lg B / lg lg B) and O(lg B) when compared to\nthe optimal layout.\n</summary>\n    <author>\n      <name>Stephen Alstrup</name>\n    </author>\n    <author>\n      <name>Michael A. Bender</name>\n    </author>\n    <author>\n      <name>Erik D. Demaine</name>\n    </author>\n    <author>\n      <name>Martin Farach-Colton</name>\n    </author>\n    <author>\n      <name>Theis Rauhe</name>\n    </author>\n    <author>\n      <name>Mikkel Thorup</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">18 pages. Version 2 adds faster dynamic programs. Preliminary version\n  appeared in European Symposium on Algorithms, 2002</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0211010v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0211010v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"E.1; F.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0211018v2</id>\n    <updated>2005-10-13T21:06:17Z</updated>\n    <published>2002-11-14T19:10:16Z</published>\n    <title>Indexing schemes for similarity search: an illustrated paradigm</title>\n    <summary>  We suggest a variation of the Hellerstein--Koutsoupias--Papadimitriou\nindexability model for datasets equipped with a similarity measure, with the\naim of better understanding the structure of indexing schemes for\nsimilarity-based search and the geometry of similarity workloads. This in\nparticular provides a unified approach to a great variety of schemes used to\nindex into metric spaces and facilitates their transfer to more general\nsimilarity measures such as quasi-metrics. We discuss links between performance\nof indexing schemes and high-dimensional geometry. The concepts and results are\nillustrated on a very large concrete dataset of peptide fragments equipped with\na biologically significant similarity measure.\n</summary>\n    <author>\n      <name>Vladimir Pestov</name>\n    </author>\n    <author>\n      <name>Aleksandar Stojmirovic</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">19 pages, LaTeX with 8 figures, prepared using Fundamenta\n  Informaticae style file</arxiv:comment>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Fundamenta Informaticae Vol. 70 (2006), No. 4, 367-385</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/0211018v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0211018v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.3.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0212044v1</id>\n    <updated>2002-12-16T09:39:16Z</updated>\n    <published>2002-12-16T09:39:16Z</published>\n    <title>Solving a \"Hard\" Problem to Approximate an \"Easy\" One: Heuristics for\n  Maximum Matchings and Maximum Traveling Salesman Problems</title>\n    <summary>  We consider geometric instances of the Maximum Weighted Matching Problem\n(MWMP) and the Maximum Traveling Salesman Problem (MTSP) with up to 3,000,000\nvertices. Making use of a geometric duality relationship between MWMP, MTSP,\nand the Fermat-Weber-Problem (FWP), we develop a heuristic approach that yields\nin near-linear time solutions as well as upper bounds. Using various\ncomputational tools, we get solutions within considerably less than 1% of the\noptimum.\n  An interesting feature of our approach is that, even though an FWP is hard to\ncompute in theory and Edmonds' algorithm for maximum weighted matching yields a\npolynomial solution for the MWMP, the practical behavior is just the opposite,\nand we can solve the FWP with high accuracy in order to find a good heuristic\nsolution for the MWMP.\n</summary>\n    <author>\n      <name>Sandor P. Fekete</name>\n    </author>\n    <author>\n      <name>Henk Meijer</name>\n    </author>\n    <author>\n      <name>Andre Rohe</name>\n    </author>\n    <author>\n      <name>Walter Tietze</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">20 pages, 14 figures, Latex, to appear in Journal of Experimental\n  Algorithms, 2002</arxiv:comment>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Journal of Experimental Algorithms, 7 (2002), article 11.</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/0212044v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0212044v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2; G.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0301019v1</id>\n    <updated>2003-01-21T17:47:05Z</updated>\n    <published>2003-01-21T17:47:05Z</published>\n    <title>Smoothed Analysis of Interior-Point Algorithms: Termination</title>\n    <summary>  We perform a smoothed analysis of the termination phase of an interior-point\nmethod. By combining this analysis with the smoothed analysis of Renegar's\ninterior-point algorithm by Dunagan, Spielman and Teng, we show that the\nsmoothed complexity of an interior-point algorithm for linear programming is $O\n(m^{3} \\log (m/\\sigma))$. In contrast, the best known bound on the worst-case\ncomplexity of linear programming is $O (m^{3} L)$, where $L$ could be as large\nas $m$. We include an introduction to smoothed analysis and a tutorial on proof\ntechniques that have been useful in smoothed analyses.\n</summary>\n    <author>\n      <name>Daniel A. Spielman</name>\n    </author>\n    <author>\n      <name>Shang-Hua Teng</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">to be presented at the 2003 International Symposium on Mathematical\n  Programming</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0301019v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0301019v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.1; G.1.6\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0301021v2</id>\n    <updated>2003-03-23T16:33:09Z</updated>\n    <published>2003-01-21T23:55:17Z</published>\n    <title>PHORMA: Perfectly Hashable Order Restricted Multidimensional Arrays</title>\n    <summary>  In this paper we propose a simple and efficient data structure yielding a\nperfect hashing of quite general arrays. The data structure is named phorma,\nwhich is an acronym for perfectly hashable order restricted multidimensional\narray.\n  Keywords: Perfect hash function, Digraph, Implicit enumeration,\nNijenhuis-Wilf combinatorial family.\n</summary>\n    <author>\n      <name>Lauro Lins</name>\n    </author>\n    <author>\n      <name>Sostenes Lins</name>\n    </author>\n    <author>\n      <name>Silvio Melo</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">12 pages, 4 figures, 2 tables. Revised version. Submitted to Discrete\n  Applied Mathematics</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0301021v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0301021v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"E.2;E.1\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0302030v2</id>\n    <updated>2004-04-19T23:32:38Z</updated>\n    <published>2003-02-20T06:36:35Z</published>\n    <title>The traveling salesman problem for cubic graphs</title>\n    <summary>  We show how to find a Hamiltonian cycle in a graph of degree at most three\nwith n vertices, in time O(2^{n/3}) ~= 1.260^n and linear space. Our algorithm\ncan find the minimum weight Hamiltonian cycle (traveling salesman problem), in\nthe same time bound. We can also count or list all Hamiltonian cycles in a\ndegree three graph in time O(2^{3n/8}) ~= 1.297^n. We also solve the traveling\nsalesman problem in graphs of degree at most four, by randomized and\ndeterministic algorithms with runtime O((27/4)^{n/3}) ~= 1.890^n and\nO((27/4+epsilon)^{n/3}) respectively. Our algorithms allow the input to specify\na set of forced edges which must be part of any generated cycle. Our cycle\nlisting algorithm shows that every degree three graph has O(2^{3n/8})\nHamiltonian cycles; we also exhibit a family of graphs with 2^{n/3} Hamiltonian\ncycles per graph.\n</summary>\n    <author>\n      <name>David Eppstein</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">20 pages, 8 figures. A preliminary version of this paper appeared at\n  the 8th Worksh. Algorithms and Data Structures, LNCS 2748, Springer-Verlag,\n  2003, pp. 307-318. This version generalizes an algorithm from the previous\n  version, to generate all cycles instead of counting them. It also includes a\n  derandomized version of the degree-four algorithm and an implementation of\n  the cycle listing algorithm</arxiv:comment>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">J. Graph Algorithms and Applications 11(1):61-81, 2007</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/0302030v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0302030v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0304005v1</id>\n    <updated>2003-04-01T23:35:11Z</updated>\n    <published>2003-04-01T23:35:11Z</published>\n    <title>Quantum Computation and Lattice Problems</title>\n    <summary>  We present the first explicit connection between quantum computation and\nlattice problems. Namely, we show a solution to the Unique Shortest Vector\nProblem (SVP) under the assumption that there exists an algorithm that solves\nthe hidden subgroup problem on the dihedral group by coset sampling. Moreover,\nwe solve the hidden subgroup problem on the dihedral group by using an average\ncase subset sum routine. By combining the two results, we get a quantum\nreduction from $\\Theta(n^{2.5})$-unique-SVP to the average case subset sum\nproblem.\n</summary>\n    <author>\n      <name>Oded Regev</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/cs/0304005v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0304005v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.1\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0306046v1</id>\n    <updated>2003-06-11T09:13:39Z</updated>\n    <published>2003-06-11T09:13:39Z</published>\n    <title>Compact Approximation of Lattice Functions with Applications to\n  Large-Alphabet Text Search</title>\n    <summary>  We propose a very simple randomised data structure that stores an\napproximation from above of a lattice-valued function. Computing the function\nvalue requires a constant number of steps, and the error probability can be\nbalanced with space usage, much like in Bloom filters. The structure is\nparticularly well suited for functions that are bottom on most of their domain.\nWe then show how to use our methods to store in a compact way the bad-character\nshift function for variants of the Boyer-Moore text search algorithms. As a\nresult, we obtain practical implementations of these algorithms that can be\nused with large alphabets, such as Unicode collation elements, with a small\nsetup time. The ideas described in this paper have been implemented as free\nsoftware under the GNU General Public License within the MG4J project\n(http://mg4j.dsi.unimi.it/).\n</summary>\n    <author>\n      <name>Paolo Boldi</name>\n    </author>\n    <author>\n      <name>Sebastiano Vigna</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/cs/0306046v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0306046v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"E.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0306104v1</id>\n    <updated>2003-06-16T21:31:36Z</updated>\n    <published>2003-06-16T21:31:36Z</published>\n    <title>Efficient pebbling for list traversal synopses</title>\n    <summary>  We show how to support efficient back traversal in a unidirectional list,\nusing small memory and with essentially no slowdown in forward steps. Using\n$O(\\log n)$ memory for a list of size $n$, the $i$'th back-step from the\nfarthest point reached so far takes $O(\\log i)$ time in the worst case, while\nthe overhead per forward step is at most $\\epsilon$ for arbitrary small\nconstant $\\epsilon&gt;0$. An arbitrary sequence of forward and back steps is\nallowed. A full trade-off between memory usage and time per back-step is\npresented: $k$ vs. $kn^{1/k}$ and vice versa. Our algorithms are based on a\nnovel pebbling technique which moves pebbles on a virtual binary, or $t$-ary,\ntree that can only be traversed in a pre-order fashion. The compact data\nstructures used by the pebbling algorithms, called list traversal synopses,\nextend to general directed graphs, and have other interesting applications,\nincluding memory efficient hash-chain implementation. Perhaps the most\nsurprising application is in showing that for any program, arbitrary rollback\nsteps can be efficiently supported with small overhead in memory, and marginal\noverhead in its ordinary execution. More concretely: Let $P$ be a program that\nruns for at most $T$ steps, using memory of size $M$. Then, at the cost of\nrecording the input used by the program, and increasing the memory by a factor\nof $O(\\log T)$ to $O(M \\log T)$, the program $P$ can be extended to support an\narbitrary sequence of forward execution and rollback steps: the $i$'th rollback\nstep takes $O(\\log i)$ time in the worst case, while forward steps take O(1)\ntime in the worst case, and $1+\\epsilon$ amortized time per step.\n</summary>\n    <author>\n      <name>Yossi Matias</name>\n    </author>\n    <author>\n      <name>Ely Porat</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">27 pages</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0306104v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0306104v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"D.2.5;E.1;E.3;I.6.7;F.2.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0306123v1</id>\n    <updated>2003-06-23T19:37:42Z</updated>\n    <published>2003-06-23T19:37:42Z</published>\n    <title>Heuristic to reduce the complexity of complete bipartite graphs to\n  accelerate the search for maximum weighted matchings with small error</title>\n    <summary>  A maximum weighted matching for bipartite graphs $G=(A \\cup B,E)$ can be\nfound by using the algorithm of Edmonds and Karp with a Fibonacci Heap and a\nmodified Dijkstra in $O(nm + n^2 \\log{n})$ time where n is the number of nodes\nand m the number of edges. For the case that $|A|=|B|$ the number of edges is\n$n^2$ and therefore the complexity is $O(n^3)$. In this paper we want to\npresent a simple heuristic method to reduce the number of edges of complete\nbipartite graphs $G=(A \\cup B,E)$ with $|A|=|B|$ such that $m = n\\log{n}$ and\ntherefore the complexity of such that $m = n\\log{n}$ and therefore the\ncomplexity of $O(n^2 \\log{n})$. The weights of all edges in G must be uniformly\ndistributed in [0,1].\n</summary>\n    <author>\n      <name>Daniel Etzold</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">5 pages, 2 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0306123v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0306123v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"G.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0307034v1</id>\n    <updated>2003-07-12T21:41:56Z</updated>\n    <published>2003-07-12T21:41:56Z</published>\n    <title>Range Mode and Range Median Queries on Lists and Trees</title>\n    <summary>  We consider algorithms for preprocessing labelled lists and trees so that,\nfor any two nodes u and v we can answer queries of the form: What is the mode\nor median label in the sequence of labels on the path from u to v.\n</summary>\n    <author>\n      <name>Danny Krizanc</name>\n    </author>\n    <author>\n      <name>Pat Morin</name>\n    </author>\n    <author>\n      <name>Michiel Smid</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">12 pages, 6 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0307034v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0307034v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"E.1\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0307043v1</id>\n    <updated>2003-07-18T04:02:18Z</updated>\n    <published>2003-07-18T04:02:18Z</published>\n    <title>An Extension of the Lovasz Local Lemma, and its Applications to Integer\n  Programming</title>\n    <summary>  The Lovasz Local Lemma due to Erdos and Lovasz is a powerful tool in proving\nthe existence of rare events. We present an extension of this lemma, which\nworks well when the event to be shown to exist is a conjunction of individual\nevents, each of which asserts that a random variable does not deviate much from\nits mean. As applications, we consider two classes of NP-hard integer programs:\nminimax and covering integer programs. A key technique, randomized rounding of\nlinear relaxations, was developed by Raghavan and Thompson to derive good\napproximation algorithms for such problems. We use our extension of the Local\nLemma to prove that randomized rounding produces, with non-zero probability,\nmuch better feasible solutions than known before, if the constraint matrices of\nthese integer programs are column-sparse (e.g., routing using short paths,\nproblems on hypergraphs with small dimension/degree). This complements certain\nwell-known results from discrepancy theory. We also generalize the method of\npessimistic estimators due to Raghavan, to obtain constructive (algorithmic)\nversions of our results for covering integer programs.\n</summary>\n    <author>\n      <name>Aravind Srinivasan</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">22 pages, preliminary version appeared in the SODA 1996 conference</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0307043v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0307043v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.1.2; F.2.2; G.2.2; G.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0308041v1</id>\n    <updated>2003-08-24T06:30:41Z</updated>\n    <published>2003-08-24T06:30:41Z</published>\n    <title>Static Data Structure for Discrete Advance Bandwidth Reservations on the\n  Internet</title>\n    <summary>  In this paper we present a discrete data structure for reservations of\nlimited resources. A reservation is defined as a tuple consisting of the time\ninterval of when the resource should be reserved, $I_R$, and the amount of the\nresource that is reserved, $B_R$, formally $R=\\{I_R,B_R\\}$.\n  The data structure is similar to a segment tree. The maximum spanning\ninterval of the data structure is fixed and defined in advance. The granularity\nand thereby the size of the intervals of the leaves is also defined in advance.\nThe data structure is built only once. Neither nodes nor leaves are ever\ninserted, deleted or moved. Hence, the running time of the operations does not\ndepend on the number of reservations previously made. The running time does not\ndepend on the size of the interval of the reservation either. Let $n$ be the\nnumber of leaves in the data structure. In the worst case, the number of\ntouched (i.e. traversed) nodes is in any operation $O(\\log n)$, hence the\nrunning time of any operation is also $O(\\log n)$.\n</summary>\n    <author>\n      <name>Andrej Brodnik</name>\n    </author>\n    <author>\n      <name>Andreas Nilsson</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/cs/0308041v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0308041v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"E.1, C.2.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0309043v1</id>\n    <updated>2003-09-23T13:45:48Z</updated>\n    <published>2003-09-23T13:45:48Z</published>\n    <title>Finding approximate palindromes in strings</title>\n    <summary>  We introduce a novel definition of approximate palindromes in strings, and\nprovide an algorithm to find all maximal approximate palindromes in a string\nwith up to $k$ errors. Our definition is based on the usual edit operations of\napproximate pattern matching, and the algorithm we give, for a string of size\n$n$ on a fixed alphabet, runs in $O(k^2 n)$ time. We also discuss two\nimplementation-related improvements to the algorithm, and demonstrate their\nefficacy in practice by means of both experiments and an average-case analysis.\n</summary>\n    <author>\n      <name>A. H. L. Porto</name>\n    </author>\n    <author>\n      <name>V. C. Barbosa</name>\n    </author>\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1016/S0031-3203(01)00179-0</arxiv:doi>\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1016/S0031-3203(01)00179-0\" rel=\"related\"/>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Pattern Recognition 35 (2002), 2581-2591</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/0309043v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0309043v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.2.2; I.2.8\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n</feed>\n"
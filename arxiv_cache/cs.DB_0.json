"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\n  <link href=\"http://arxiv.org/api/query?search_query%3Dcat%3Acs.DB%26id_list%3D%26start%3D0%26max_results%3D50\" rel=\"self\" type=\"application/atom+xml\"/>\n  <title type=\"html\">ArXiv Query: search_query=cat:cs.DB&amp;id_list=&amp;start=0&amp;max_results=50</title>\n  <id>http://arxiv.org/api/J527tMEw9v2MriGE3gdhhHNfuXg</id>\n  <updated>2025-03-22T00:00:00-04:00</updated>\n  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">9716</opensearch:totalResults>\n  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\n  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">50</opensearch:itemsPerPage>\n  <entry>\n    <id>http://arxiv.org/abs/cs/9809005v1</id>\n    <updated>1998-09-02T01:49:32Z</updated>\n    <published>1998-09-02T01:49:32Z</published>\n    <title>The Five-Minute Rule Ten Years Later, and Other Computer Storage Rules\n  of Thumb</title>\n    <summary>  Simple economic and performance arguments suggest appropriate lifetimes for\nmain memory pages and suggest optimal page sizes. The fundamental tradeoffs are\nthe prices and bandwidths of RAMs and disks. The analysis indicates that with\ntoday's technology, five minutes is a good lifetime for randomly accessed\npages, one minute is a good lifetime for two-pass sequentially accessed pages,\nand 16 KB is a good size for index pages. These rules-of-thumb change in\npredictable ways as technology ratios change. They also motivate the importance\nof the new Kaps, Maps, Scans, and $/Kaps, $/Maps, $/TBscan metrics.\n</summary>\n    <author>\n      <name>Jim Gray</name>\n    </author>\n    <author>\n      <name>Goetz Graefe</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Original document at:\n  http://research.microsoft.com/~gray/5_min_rule_SIGMOD.doc</arxiv:comment>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">ACM SIGMOD Record 26(4): 63-68 (1997)</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/9809005v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/9809005v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.3.4\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/9809023v2</id>\n    <updated>1998-09-18T19:04:42Z</updated>\n    <published>1998-09-17T14:41:07Z</published>\n    <title>Similarity-Based Queries for Time Series Data</title>\n    <summary>  We study a set of linear transformations on the Fourier series representation\nof a sequence that can be used as the basis for similarity queries on\ntime-series data. We show that our set of transformations is rich enough to\nformulate operations such as moving average and time warping. We present a\nquery processing algorithm that uses the underlying R-tree index of a\nmultidimensional data set to answer similarity queries efficiently. Our\nexperiments show that the performance of this algorithm is competitive to that\nof processing ordinary (exact match) queries using the index, and much faster\nthan sequential scanning. We relate our transformations to the general\nframework for similarity queries of Jagadish et al.\n</summary>\n    <author>\n      <name>Davood Rafiei</name>\n    </author>\n    <author>\n      <name>Alberto Mendelzon</name>\n    </author>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">In Proceedings of the ACM SIGMOD Intl. Conf. on Management of\n  Data, pages 13-24, Tucson, Arizona, May 1997</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/9809023v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/9809023v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/9809033v2</id>\n    <updated>1998-09-25T16:12:20Z</updated>\n    <published>1998-09-18T21:24:23Z</published>\n    <title>Efficient Retrieval of Similar Time Sequences Using DFT</title>\n    <summary>  We propose an improvement of the known DFT-based indexing technique for fast\nretrieval of similar time sequences. We use the last few Fourier coefficients\nin the distance computation without storing them in the index since every\ncoefficient at the end is the complex conjugate of a coefficient at the\nbeginning and as strong as its counterpart. We show analytically that this\nobservation can accelerate the search time of the index by more than a factor\nof two. This result was confirmed by our experiments, which were carried out on\nreal stock prices and synthetic data.\n</summary>\n    <author>\n      <name>Davood Rafiei</name>\n    </author>\n    <author>\n      <name>Alberto Mendelzon</name>\n    </author>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Proceedings of 5th Intl. Conf. on Foundations of Data\n  Organizations and Algorithms (FODO '98), November 1998, Kobe, Japan</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/9809033v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/9809033v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2;H.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/9909016v1</id>\n    <updated>1999-09-21T21:20:20Z</updated>\n    <published>1999-09-21T21:20:20Z</published>\n    <title>Least expected cost query optimization: an exercise in utility</title>\n    <summary>  We identify two unreasonable, though standard, assumptions made by database\nquery optimizers that can adversely affect the quality of the chosen evaluation\nplans. One assumption is that it is enough to optimize for the expected\ncase---that is, the case where various parameters (like available memory) take\non their expected value. The other assumption is that the parameters are\nconstant throughout the execution of the query. We present an algorithm based\non the ``System R''-style query optimization algorithm that does not rely on\nthese assumptions. The algorithm we present chooses the plan of the least\nexpected cost instead of the plan of least cost given some fixed value of the\nparameters. In execution environments that exhibit a high degree of\nvariability, our techniques should result in better performance.\n</summary>\n    <author>\n      <name>Francis C. Chu</name>\n    </author>\n    <author>\n      <name>Joseph Y. Halpern</name>\n    </author>\n    <author>\n      <name>Praveen Seshadri</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">This paper appears in Proceedings of the Eighteenth Annual ACM\n  Symposium on Principles of Database Systems, 1999, pp. 138--147</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/9909016v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/9909016v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.4\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/9910021v1</id>\n    <updated>1999-10-25T16:30:20Z</updated>\n    <published>1999-10-25T16:30:20Z</published>\n    <title>Efficient and Extensible Algorithms for Multi Query Optimization</title>\n    <summary>  Complex queries are becoming commonplace, with the growing use of decision\nsupport systems. These complex queries often have a lot of common\nsub-expressions, either within a single query, or across multiple such queries\nrun as a batch. Multi-query optimization aims at exploiting common\nsub-expressions to reduce evaluation cost. Multi-query optimization has\nhither-to been viewed as impractical, since earlier algorithms were exhaustive,\nand explore a doubly exponential search space.\n  In this paper we demonstrate that multi-query optimization using heuristics\nis practical, and provides significant benefits. We propose three cost-based\nheuristic algorithms: Volcano-SH and Volcano-RU, which are based on simple\nmodifications to the Volcano search strategy, and a greedy heuristic. Our\ngreedy heuristic incorporates novel optimizations that improve efficiency\ngreatly. Our algorithms are designed to be easily added to existing optimizers.\nWe present a performance study comparing the algorithms, using workloads\nconsisting of queries from the TPC-D benchmark. The study shows that our\nalgorithms provide significant benefits over traditional optimization, at a\nvery acceptable overhead in optimization time.\n</summary>\n    <author>\n      <name>Prasan Roy</name>\n    </author>\n    <author>\n      <name>S. Seshadri</name>\n    </author>\n    <author>\n      <name>S. Sudarshan</name>\n    </author>\n    <author>\n      <name>Siddhesh Bhobe</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/cs/9910021v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/9910021v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.4;H.2.7\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/9912015v1</id>\n    <updated>1999-12-22T15:25:55Z</updated>\n    <published>1999-12-22T15:25:55Z</published>\n    <title>Comparative Analysis of Five XML Query Languages</title>\n    <summary>  XML is becoming the most relevant new standard for data representation and\nexchange on the WWW. Novel languages for extracting and restructuring the XML\ncontent have been proposed, some in the tradition of database query languages\n(i.e. SQL, OQL), others more closely inspired by XML. No standard for XML query\nlanguage has yet been decided, but the discussion is ongoing within the World\nWide Web Consortium and within many academic institutions and Internet-related\nmajor companies. We present a comparison of five, representative query\nlanguages for XML, highlighting their common features and differences.\n</summary>\n    <author>\n      <name>Angela Bonifati</name>\n    </author>\n    <author>\n      <name>Stefano Ceri</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">TeX v3.1415, 17 pages, 6 figures, to be published in ACM Sigmod\n  Record, March 2000</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/9912015v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/9912015v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2; H.2.3; I.7; I.7.1; I.7.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0003005v1</id>\n    <updated>2000-03-02T08:15:21Z</updated>\n    <published>2000-03-02T08:15:21Z</published>\n    <title>Don't Trash your Intermediate Results, Cache 'em</title>\n    <summary>  In data warehouse and data mart systems, queries often take a long time to\nexecute due to their complex nature. Query response times can be greatly\nimproved by caching final/intermediate results of previous queries, and using\nthem to answer later queries. In this paper we describe a caching system called\nExchequer which incorporates several novel features including optimization\naware cache maintenance and the use of a cache aware optimizer. In contrast, in\nexisting work, the module that makes cost-benefit decisions is part of the\ncache manager and works independent of the optimizer which essentially\nreconsiders these decisions while finding the best plan for a query. In our\nwork, the optimizer takes the decisions for the cache manager. Furthermore,\nexisting approaches are either restricted to cube (slice/point) queries, or\ncache just the query results. On the other hand, our work is extens ible and in\nfact presents a data-model independent framework and algorithm. Our\nexperimental results attest to the efficacy of our cache management techniques\nand show that over a wide range of parameters (a) Exchequer's query response\ntimes are lower by more than 30% compared to the best performing competitor,\nand (b) Exchequer can deliver the same response time as its competitor with\njust one tenth of the cache size.\n</summary>\n    <author>\n      <name>Prasan Roy</name>\n    </author>\n    <author>\n      <name>Krithi Ramamritham</name>\n    </author>\n    <author>\n      <name>S. Seshadri</name>\n    </author>\n    <author>\n      <name>Pradeep Shenoy</name>\n    </author>\n    <author>\n      <name>S. Sudarshan</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">22 pages, 4 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0003005v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0003005v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.4;H.2.7\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0003006v1</id>\n    <updated>2000-03-02T08:05:24Z</updated>\n    <published>2000-03-02T08:05:24Z</published>\n    <title>Materialized View Selection and Maintenance Using Multi-Query\n  Optimization</title>\n    <summary>  Because the presence of views enhances query performance, materialized views\nare increasingly being supported by commercial database/data warehouse systems.\nWhenever the data warehouse is updated, the materialized views must also be\nupdated. However, whereas the amount of data entering a warehouse, the query\nloads, and the need to obtain up-to-date responses are all increasing, the time\nwindow available for making the warehouse up-to-date is shrinking. These trends\nnecessitate efficient techniques for the maintenance of materialized views.\n  In this paper, we show how to find an efficient plan for maintenance of a\n{\\em set} of views, by exploiting common subexpressions between different view\nmaintenance expressions. These common subexpressions may be materialized\ntemporarily during view maintenance. Our algorithms also choose\nsubexpressions/indices to be materialized permanently (and maintained along\nwith other materialized views), to speed up view maintenance. While there has\nbeen much work on view maintenance in the past, our novel contributions lie in\nexploiting a recently developed framework for multiquery optimization to\nefficiently find good view maintenance plans as above. In addition to faster\nview maintenance, our algorithms can also be used to efficiently select\nmaterialized views to speed up workloads containing queries.\n</summary>\n    <author>\n      <name>Hoshi Mistry</name>\n    </author>\n    <author>\n      <name>Prasan Roy</name>\n    </author>\n    <author>\n      <name>Krithi Ramamritham</name>\n    </author>\n    <author>\n      <name>S. Sudarshan</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">22 pages, 7 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0003006v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0003006v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.4;H.2.7\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0007044v2</id>\n    <updated>2001-06-11T08:13:05Z</updated>\n    <published>2000-07-31T20:15:08Z</published>\n    <title>Managing Periodically Updated Data in Relational Databases: A Stochastic\n  Modeling Approach</title>\n    <summary>  Recent trends in information management involve the periodic transcription of\ndata onto secondary devices in a networked environment, and the proper\nscheduling of these transcriptions is critical for efficient data management.\nTo assist in the scheduling process, we are interested in modeling the\nreduction of consistency over time between a relation and its replica, termed\nobsolescence of data. The modeling is based on techniques from the field of\nstochastic processes, and provides several stochastic models for content\nevolution in the base relations of a database, taking referential integrity\nconstraints into account. These models are general enough to accommodate most\nof the common scenarios in databases, including batch insertions and life spans\nboth with and without memory. As an initial \"proof of concept\" of the\napplicability of our approach, we validate the insertion portion of our model\nframework via experiments with real data feeds. We also discuss a set of\ntranscription protocols which make use of the proposed stochastic model.\n</summary>\n    <author>\n      <name>Avigdor Gal</name>\n    </author>\n    <author>\n      <name>Jonathan Eckstein</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/cs/0007044v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0007044v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.4\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0011024v1</id>\n    <updated>2000-11-17T12:16:43Z</updated>\n    <published>2000-11-17T12:16:43Z</published>\n    <title>Algorithms for Rewriting Aggregate Queries Using Views</title>\n    <summary>  Queries involving aggregation are typical in database applications. One of\nthe main ideas to optimize the execution of an aggregate query is to reuse\nresults of previously answered queries. This leads to the problem of rewriting\naggregate queries using views. Due to a lack of theory, algorithms for this\nproblem were rather ad-hoc. They were sound, but were not proven to be\ncomplete.\n  Recently we have given syntactic characterizations for the equivalence of\naggregate queries and applied them to decide when there exist rewritings.\nHowever, these decision procedures do not lend themselves immediately to an\nimplementation. In this paper, we present practical algorithms for rewriting\nqueries with $\\COUNT$ and $\\SUM$. Our algorithms are sound. They are also\ncomplete for important cases. Our techniques can be used to improve well-known\nprocedures for rewriting non-aggregate queries. These procedures can then be\nadapted to obtain algorithms for rewriting queries with $\\MIN$ and $\\MAX$. The\nalgorithms presented are a basis for realizing optimizers that rewrite queries\nusing views.\n</summary>\n    <author>\n      <name>Sara Cohen</name>\n    </author>\n    <author>\n      <name>Werner Nutt</name>\n    </author>\n    <author>\n      <name>Alexander Serebrenik</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">technical report CW 292 of Katholieke Universiteit Leuven (Short\n  version in In Julius Stuller, Jaroslav Pokorn?, Bernhard Thalheim, Yoshifumi\n  Masunaga (Eds.): Current Issues in Databases and Information Systems,\n  East-European Conference on Advances in Databases and Information Systems\n  Held Jointly with International Conference on Database Systems for Advanced\n  Applications, ADBIS-DASFAA 2000, Prague, Czech Republic, September 5-8,\n  2000.)</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0011024v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0011024v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0011041v1</id>\n    <updated>2000-11-27T09:15:08Z</updated>\n    <published>2000-11-27T09:15:08Z</published>\n    <title>EquiX---A Search and Query Language for XML</title>\n    <summary>  EquiX is a search language for XML that combines the power of querying with\nthe simplicity of searching. Requirements for such languages are discussed and\nit is shown that EquiX meets the necessary criteria. Both a graphical abstract\nsyntax and a formal concrete syntax are presented for EquiX queries. In\naddition, the semantics is defined and an evaluation algorithm is presented.\nThe evaluation algorithm is polynomial under combined complexity.\n  EquiX combines pattern matching, quantification and logical expressions to\nquery both the data and meta-data of XML documents. The result of a query in\nEquiX is a set of XML documents. A DTD describing the result documents is\nderived automatically from the query.\n</summary>\n    <author>\n      <name>Sara Cohen</name>\n    </author>\n    <author>\n      <name>Yaron Kanza</name>\n    </author>\n    <author>\n      <name>Yakov Kogan</name>\n    </author>\n    <author>\n      <name>Werner Nutt</name>\n    </author>\n    <author>\n      <name>Yehoshua Sagiv</name>\n    </author>\n    <author>\n      <name>Alexander Serebrenik</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">technical report of Hebrew University Jerusalem Israel</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0011041v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0011041v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0103004v1</id>\n    <updated>2001-03-02T20:00:16Z</updated>\n    <published>2001-03-02T20:00:16Z</published>\n    <title>Rapid Application Evolution and Integration Through Document\n  Metamorphosis</title>\n    <summary>  The Harland document management system implements a data model in which\ndocument (object) structure can be altered by mixin-style multiple inheritance\nat any time. This kind of structural fluidity has long been supported by\nknowledge-base management systems, but its use has primarily been in support of\nreasoning and inference. In this paper, we report our experiences building and\nsupporting several non-trivial applications on top of this data model. Based on\nthese experiences, we argue that structural fluidity is convenient for\ndata-intensive applications other than knowledge-base management. Specifically,\nwe suggest that this flexible data model is a natural fit for the decoupled\nprogramming methodology that arises naturally when using enterprise component\nframeworks.\n</summary>\n    <author>\n      <name>Paul M. Aoki</name>\n    </author>\n    <author>\n      <name>Ian E. Smith</name>\n    </author>\n    <author>\n      <name>James D. Thornton</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/cs/0103004v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0103004v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.3; D.2.11; K.6.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0106055v1</id>\n    <updated>2001-06-28T06:02:46Z</updated>\n    <published>2001-06-28T06:02:46Z</published>\n    <title>A Seamless Integration of Association Rule Mining with Database Systems</title>\n    <summary>  The need for Knowledge and Data Discovery Management Systems (KDDMS) that\nsupport ad hoc data mining queries has been long recognized. A significant\namount of research has gone into building tightly coupled systems that\nintegrate association rule mining with database systems. In this paper, we\ndescribe a seamless integration scheme for database queries and association\nrule discovery using a common query optimizer for both. Query trees of\nexpressions in an extended algebra are used for internal representation in the\noptimizer. The algebraic representation is flexible enough to deal with\nconstrained association rule queries and other variations of association rule\nspecifications. We propose modularization to simplify the query tree for\ncomplex tasks in data mining. It paves the way for making use of existing\nalgorithms for constructing query plans in the optimization process. How the\nintegration scheme we present will facilitate greater user control over the\ndata mining process is also discussed. The work described in this paper forms\npart of a larger project for fully integrating data mining with database\nmanagement.\n</summary>\n    <author>\n      <name>Raj P. Gopalan</name>\n    </author>\n    <author>\n      <name>Tariq Nuruddin</name>\n    </author>\n    <author>\n      <name>Yudho Giri Sucahyo</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">15 pages</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0106055v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0106055v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.8\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0109084v1</id>\n    <updated>2001-09-24T20:42:05Z</updated>\n    <published>2001-09-24T20:42:05Z</published>\n    <title>The Internet and Community Networks: Case Studies of Five U.S. Cities</title>\n    <summary>  This paper looks at five U.S. cities (Austin, Cleveland, Nashville, Portland,\nand Washington, DC) and explores strategies being employed by community\nactivists and local governments to create and sustain community networking\nprojects. In some cities, community networking initiatives are relatively\nmature, while in others they are in early or intermediate stages. The paper\nlooks at several factors that help explain the evolution of community networks\nin cities:\n  1) Local government support; 2) Federal support 3) Degree of community\nactivism, often reflected by public-private partnerships that help support\ncommunity networks.\n  In addition to these (more or less) measurable elements of local support, the\ncase studies enable description of the different objectives of community\nnetworks in different cities. Several community networking projects aim to\nimprove the delivery of government services (e.g., Portland and Cleveland),\nsome have a job-training focus (e.g., Austin, Washington, DC), others are\noriented very explicitly toward community building (Nashville, DC), and others\ntoward neighborhood entrepreneurship (Portland and Cleveland).\n  The paper ties the case studies together by asking whether community\ntechnology initiatives contribute to social capital in the cities studied.\n</summary>\n    <author>\n      <name>John B. Horrigan</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">29th TPRC Conference</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0109084v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0109084v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"K.4.m Miscellaneous\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0110020v1</id>\n    <updated>2001-10-08T06:29:14Z</updated>\n    <published>2001-10-08T06:29:14Z</published>\n    <title>Structuring Business Metadata in Data Warehouse Systems for Effective\n  Business Support</title>\n    <summary>  Large organizations today are being served by different types of data\nprocessing and informations systems, ranging from the operational (OLTP)\nsystems, data warehouse systems, to data mining and business intelligence\napplications. It is important to create an integrated repository of what these\nsystems contain and do in order to use them collectively and effectively. The\nrepository contains metadata of source systems, data warehouse, and also the\nbusiness metadata. Decision support and business analysis require extensive and\nin-depth understanding of business entities, tasks, rules and the environment.\nThe purpose of business metadata is to provide this understanding. Realizing\nthe importance of metadata, many standardization efforts has been initiated to\ndefine metadata models. In trying to define an integrated metadata and\ninformation systems for a banking application, we discover some important\nlimitations or inadequacies of the business metadata proposals. They relate to\nproviding an integrated and flexible inter-operability and navigation between\nmetadata and data, and to the important issue of systematically handling\ntemporal characteristics and evolution of the metadata itself.\n  In this paper, we study the issue of structuring business metadata so that it\ncan provide a context for business management and decision support when\nintegrated with data warehousing. We define temporal object-oriented business\nmetadata model, and relate it both to the technical metadata and the data\nwarehouse. We also define ways of accessing and navigating metadata in\nconjunction with data.\n</summary>\n    <author>\n      <name>N. L. Sarda</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/cs/0110020v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0110020v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.1, H.2.7\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0110044v1</id>\n    <updated>2001-10-22T08:03:50Z</updated>\n    <published>2001-10-22T08:03:50Z</published>\n    <title>EquiX--A Search and Query Language for XML</title>\n    <summary>  EquiX is a search language for XML that combines the power of querying with\nthe simplicity of searching. Requirements for such languages are discussed and\nit is shown that EquiX meets the necessary criteria. Both a graph-based\nabstract syntax and a formal concrete syntax are presented for EquiX queries.\nIn addition, the semantics is defined and an evaluation algorithm is presented.\nThe evaluation algorithm is polynomial under combined complexity.\n  EquiX combines pattern matching, quantification and logical expressions to\nquery both the data and meta-data of XML documents. The result of a query in\nEquiX is a set of XML documents. A DTD describing the result documents is\nderived automatically from the query.\n</summary>\n    <author>\n      <name>Sara Cohen</name>\n    </author>\n    <author>\n      <name>Yaron Kanza</name>\n    </author>\n    <author>\n      <name>Yakov Kogan</name>\n    </author>\n    <author>\n      <name>Werner Nutt</name>\n    </author>\n    <author>\n      <name>Yehoshua Sagiv</name>\n    </author>\n    <author>\n      <name>Alexander Serebrenik</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">This is a preprint of an article accepted for publication in Journal\n  of the American Society for Information Science and Technology @ copyright\n  2001 John Wiley &amp; Sons, Inc</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0110044v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0110044v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.5; H.2.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0110052v1</id>\n    <updated>2001-10-25T08:55:57Z</updated>\n    <published>2001-10-25T08:55:57Z</published>\n    <title>Mragyati : A System for Keyword-based Searching in Databases</title>\n    <summary>  The web, through many search engine sites, has popularized the keyword-based\nsearch paradigm, where a user can specify a string of keywords and expect to\nretrieve relevant documents, possibly ranked by their relevance to the query.\nSince a lot of information is stored in databases (and not as HTML documents),\nit is important to provide a similar search paradigm for databases, where users\ncan query a database without knowing the database schema and database query\nlanguages such as SQL. In this paper, we propose such a database search system,\nwhich accepts a free-form query as a collection of keywords, translates it into\nqueries on the database using the database metadata, and presents query results\nin a well-structured and browsable form. Th eysytem maps keywords onto the\ndatabase schema and uses inter-relationships (i.e., data semantics) among the\nreferred tables to generate meaningful query results. We also describe our\nprototype for database search, called Mragyati. Th eapproach proposed here is\nscalable, as it does not build an in-memory graph of the entire database for\nsearching for relationships among the objects selected by the user's query.\n</summary>\n    <author>\n      <name>N. L. Sarda</name>\n    </author>\n    <author>\n      <name>Ankur Jain</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/cs/0110052v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0110052v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.4; H.3.3; H.3.5\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0111004v1</id>\n    <updated>2001-11-01T22:07:01Z</updated>\n    <published>2001-11-01T22:07:01Z</published>\n    <title>The Relational Database Aspects of Argonne's ATLAS Control System</title>\n    <summary>  The Relational Database Aspects of Argonnes ATLAS Control System Argonnes\nATLAS (Argonne Tandem Linac Accelerator System) control system comprises two\nseparate database concepts. The first is the distributed real-time database\nstructure provided by the commercial product Vsystem [1]. The second is a more\nstatic relational database archiving system designed by ATLAS personnel using\nOracle Rdb [2] and Paradox [3] software. The configuration of the ATLAS\nfacility has presented a unique opportunity to construct a control system\nrelational database that is capable of storing and retrieving complete archived\ntune-up configurations for the entire accelerator. This capability has been a\nmajor factor in allowing the facility to adhere to a rigorous operating\nschedule. Most recently, a Web-based operator interface to the control systems\nOracle Rdb database has been installed. This paper explains the history of the\nATLAS database systems, how they interact with each other, the design of the\nnew Web-based operator interface, and future plans.\n</summary>\n    <author>\n      <name>D. E. R. Quock</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">ANL</arxiv:affiliation>\n    </author>\n    <author>\n      <name>F. H. Munson</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">ANL</arxiv:affiliation>\n    </author>\n    <author>\n      <name>K. J. Eder</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">ANL</arxiv:affiliation>\n    </author>\n    <author>\n      <name>S. L. Dean</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">ANL</arxiv:affiliation>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">ICALEPCS 2001 Conference, PSN WEAP066, 3 pages, 3 figures</arxiv:comment>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">eConf C011127 (2001) WEAP066</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/0111004v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0111004v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"C.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0111006v1</id>\n    <updated>2001-11-05T18:14:16Z</updated>\n    <published>2001-11-05T18:14:16Z</published>\n    <title>Proliferation of SDDS Support for Various Platforms and Languages</title>\n    <summary>  Since Self-Describing Data Sets (SDDS) were first introduced, the source code\nhas been ported to many different operating systems and various languages. SDDS\nis now available in C, Tcl, Java, Fortran, and Python. All of these versions\nare supported on Solaris, Linux, and Windows. The C version of SDDS is also\nsupported on VxWorks. With the recent addition of the Java port, SDDS can now\nbe deployed on virtually any operating system. Due to this proliferation, SDDS\nfiles serve to link not only a collection of C programs, but programs and\nscripts in many languages on different operating systems. The platform\nindependent binary feature of SDDS also facilitates portability among operating\nsystems. This paper presents an overview of various benefits of SDDS platform\ninteroperability.\n</summary>\n    <author>\n      <name>Robert Soliday</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">APS/ANL</arxiv:affiliation>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">3 pages, 2 figures, submitted to ICALEPCS 2001</arxiv:comment>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">eConfC011127:THAP031,2001</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/0111006v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0111006v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.8\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0202035v1</id>\n    <updated>2002-02-21T05:23:51Z</updated>\n    <published>2002-02-21T05:23:51Z</published>\n    <title>Sprinkling Selections over Join DAGs for Efficient Query Optimization</title>\n    <summary>  In optimizing queries, solutions based on AND/OR DAG can generate all\npossible join orderings and select placements before searching for optimal\nquery execution strategy. But as the number of joins and selection conditions\nincrease, the space and time complexity to generate optimal query plan\nincreases exponentially. In this paper, we use join graph for a relational\ndatabase schema to either pre-compute all possible join orderings that can be\nexecuted and store it as a join DAG or, extract joins in the queries to\nincrementally build a history join DAG as and when the queries are executed.\nThe select conditions in the queries are appropriately placed in the retrieved\njoin DAG (or, history join DAG) to generate optimal query execution strategy.\nWe experimentally evaluate our query optimization technique on TPC-D/H query\nsets to show their effectiveness over AND/OR DAG query optimization strategy.\nFinally, we illustrate how our technique can be used for efficient multiple\nquery optimization and selection of materialized views in data warehousing\nenvironments.\n</summary>\n    <author>\n      <name>Satyanarayana R Valluri</name>\n    </author>\n    <author>\n      <name>Soujanya Vadapalli</name>\n    </author>\n    <author>\n      <name>Kamalakar Karlapalem</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">12 Pages</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0202035v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0202035v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.4\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0202037v2</id>\n    <updated>2003-10-13T12:29:04Z</updated>\n    <published>2002-02-25T19:35:12Z</published>\n    <title>Towards practical meta-querying</title>\n    <summary>  We describe a meta-querying system for databases containing queries in\naddition to ordinary data. In the context of such databases, a meta-query is a\nquery about queries. Representing stored queries in XML, and using the standard\nXML manipulation language XSLT as a sublanguage, we show that just a few\nfeatures need to be added to SQL to turn it into a fully-fledged meta-query\nlanguage. The good news is that these features can be directly supported by\nextensible database technology.\n</summary>\n    <author>\n      <name>Jan Van den Bussche</name>\n    </author>\n    <author>\n      <name>Stijn Vansummeren</name>\n    </author>\n    <author>\n      <name>Gottfried Vossen</name>\n    </author>\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1016/j.is.2004.04.001</arxiv:doi>\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1016/j.is.2004.04.001\" rel=\"related\"/>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Includes a new section \"Experimental performance evaluation\"</arxiv:comment>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Information Systems, Volume 30, Issue 4 , June 2005, Pages 317-332</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/0202037v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0202037v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0204010v1</id>\n    <updated>2002-04-05T22:24:33Z</updated>\n    <published>2002-04-05T22:24:33Z</published>\n    <title>On the Computational Complexity of Consistent Query Answers</title>\n    <summary>  We consider here the problem of obtaining reliable, consistent information\nfrom inconsistent databases -- databases that do not have to satisfy given\nintegrity constraints. We use the notion of consistent query answer -- a query\nanswer which is true in every (minimal) repair of the database. We provide a\ncomplete classification of the computational complexity of consistent answers\nto first-order queries w.r.t. functional dependencies and denial constraints.\nWe show how the complexity depends on the {\\em type} of the constraints\nconsidered, their {\\em number}, and the {\\em size} of the query. We obtain\nseveral new PTIME cases, using new algorithms.\n</summary>\n    <author>\n      <name>Jan Chomicki</name>\n    </author>\n    <author>\n      <name>Jerzy Marcinkowski</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">9 pages</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0204010v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0204010v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.3; F.4.1; I.2.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0205060v1</id>\n    <updated>2002-05-23T14:15:55Z</updated>\n    <published>2002-05-23T14:15:55Z</published>\n    <title>Optimizing Queries Using a Meta-level Database</title>\n    <summary>  Graph simulation (using graph schemata or data guides) has been successfully\nproposed as a technique for adding structure to semistructured data. Design\npatterns for description (such as meta-classes and homomorphisms between schema\nlayers), which are prominent in the object-oriented programming community,\nconstitute a generalization of this graph simulation approach.\n  In this paper, we show description applicable to a wide range of data models\nthat have some notion of object (-identity), and propose to turn it into a data\nmodel primitive much like, say, inheritance. We argue that such an extension\nfills a practical need in contemporary data management. Then, we present\nalgebraic techniques for query optimization (using the notions of described and\ndescription queries). Finally, in the semistructured setting, we discuss the\npruning of regular path queries (with nested conditions) using description\nmeta-data. In this context, our notion of meta-data extends graph schemata and\ndata guides by meta-level values, allowing to boost query performance and to\nreduce the redundancy of data.\n</summary>\n    <author>\n      <name>Christoph Koch</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">26 pages, 5 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0205060v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0205060v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.1, H.2.3, D.1.5, D.3.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0207093v1</id>\n    <updated>2002-07-27T00:46:50Z</updated>\n    <published>2002-07-27T00:46:50Z</published>\n    <title>Preference Queries</title>\n    <summary>  The handling of user preferences is becoming an increasingly important issue\nin present-day information systems. Among others, preferences are used for\ninformation filtering and extraction to reduce the volume of data presented to\nthe user. They are also used to keep track of user profiles and formulate\npolicies to improve and automate decision making.\n  We propose here a simple, logical framework for formulating preferences as\npreference formulas. The framework does not impose any restrictions on the\npreference relations and allows arbitrary operation and predicate signatures in\npreference formulas. It also makes the composition of preference relations\nstraightforward. We propose a simple, natural embedding of preference formulas\ninto relational algebra (and SQL) through a single winnow operator\nparameterized by a preference formula. The embedding makes possible the\nformulation of complex preference queries, e.g., involving aggregation, by\npiggybacking on existing SQL constructs. It also leads in a natural way to the\ndefinition of further, preference-related concepts like ranking. Finally, we\npresent general algebraic laws governing the winnow operator and its\ninteraction with other relational algebra operators. The preconditions on the\napplicability of the laws are captured by logical formulas. The laws provide a\nformal foundation for the algebraic optimization of preference queries. We\ndemonstrate the usefulness of our approach through numerous examples.\n</summary>\n    <author>\n      <name>Jan Chomicki</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">34 pages</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0207093v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0207093v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.3; F.4.1; I.2.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0207094v1</id>\n    <updated>2002-07-26T21:18:50Z</updated>\n    <published>2002-07-26T21:18:50Z</published>\n    <title>Answer Sets for Consistent Query Answering in Inconsistent Databases</title>\n    <summary>  A relational database is inconsistent if it does not satisfy a given set of\nintegrity constraints. Nevertheless, it is likely that most of the data in it\nis consistent with the constraints. In this paper we apply logic programming\nbased on answer sets to the problem of retrieving consistent information from a\npossibly inconsistent database. Since consistent information persists from the\noriginal database to every of its minimal repairs, the approach is based on a\nspecification of database repairs using disjunctive logic programs with\nexceptions, whose answer set semantics can be represented and computed by\nsystems that implement stable model semantics. These programs allow us to\ndeclare persistence by defaults and repairing changes by exceptions. We\nconcentrate mainly on logic programs for binary integrity constraints, among\nwhich we find most of the integrity constraints found in practice.\n</summary>\n    <author>\n      <name>Marcelo Arenas</name>\n    </author>\n    <author>\n      <name>Leopoldo Bertossi</name>\n    </author>\n    <author>\n      <name>Jan Chomicki</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">34 pages</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0207094v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0207094v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.3; F.4.1; I.2.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0211020v2</id>\n    <updated>2003-10-08T01:17:47Z</updated>\n    <published>2002-11-15T20:01:54Z</published>\n    <title>Monadic Datalog and the Expressive Power of Languages for Web\n  Information Extraction</title>\n    <summary>  Research on information extraction from Web pages (wrapping) has seen much\nactivity recently (particularly systems implementations), but little work has\nbeen done on formally studying the expressiveness of the formalisms proposed or\non the theoretical foundations of wrapping. In this paper, we first study\nmonadic datalog over trees as a wrapping language. We show that this simple\nlanguage is equivalent to monadic second order logic (MSO) in its ability to\nspecify wrappers. We believe that MSO has the right expressiveness required for\nWeb information extraction and propose MSO as a yardstick for evaluating and\ncomparing wrappers. Along the way, several other results on the complexity of\nquery evaluation and query containment for monadic datalog over trees are\nestablished, and a simple normal form for this language is presented. Using the\nabove results, we subsequently study the kernel fragment Elog$^-$ of the Elog\nwrapping language used in the Lixto system (a visual wrapper generator).\nCuriously, Elog$^-$ exactly captures MSO, yet is easier to use. Indeed,\nprograms in this language can be entirely visually specified.\n</summary>\n    <author>\n      <name>Georg Gottlob</name>\n    </author>\n    <author>\n      <name>Christoph Koch</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">40 pages, 3 figures, journal version of PODS 2002 paper, to appear in\n  JACM</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0211020v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0211020v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.1.1; F.4.1; F.4.3; H.2.3; I.7.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0212004v1</id>\n    <updated>2002-12-05T16:23:35Z</updated>\n    <published>2002-12-05T16:23:35Z</published>\n    <title>Minimal-Change Integrity Maintenance Using Tuple Deletions</title>\n    <summary>  We address the problem of minimal-change integrity maintenance in the context\nof integrity constraints in relational databases. We assume that\nintegrity-restoration actions are limited to tuple deletions. We identify two\nbasic computational issues: repair checking (is a database instance a repair of\na given database?) and consistent query answers (is a tuple an answer to a\ngiven query in every repair of a given database?). We study the computational\ncomplexity of both problems, delineating the boundary between the tractable and\nthe intractable. We consider denial constraints, general functional and\ninclusion dependencies, as well as key and foreign key constraints. Our results\nshed light on the computational feasibility of minimal-change integrity\nmaintenance. The tractable cases should lead to practical implementations. The\nintractability results highlight the inherent limitations of any integrity\nenforcement mechanism, e.g., triggers or referential constraint actions, as a\nway of performing minimal-change integrity maintenance.\n</summary>\n    <author>\n      <name>Jan Chomicki</name>\n    </author>\n    <author>\n      <name>Jerzy Marcinkowski</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/cs/0212004v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0212004v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.3; F.4.1; I.2.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0212017v1</id>\n    <updated>2002-12-09T17:29:12Z</updated>\n    <published>2002-12-09T17:29:12Z</published>\n    <title>Classes of Spatiotemporal Objects and Their Closure Properties</title>\n    <summary>  We present a data model for spatio-temporal databases. In this model\nspatio-temporal data is represented as a finite union of objects described by\nmeans of a spatial reference object, a temporal object and a geometric\ntransformation function that determines the change or movement of the reference\nobject in time.\n  We define a number of practically relevant classes of spatio-temporal\nobjects, and give complete results concerning closure under Boolean set\noperators for these classes. Since only few classes are closed under all set\noperators, we suggest an extension of the model, which leads to better closure\nproperties, and therefore increased practical applicability. We also discuss a\nnormal form for this extended data model.\n</summary>\n    <author>\n      <name>Jan Chomicki</name>\n    </author>\n    <author>\n      <name>Sofie Haesevoets</name>\n    </author>\n    <author>\n      <name>Bart Kuijpers</name>\n    </author>\n    <author>\n      <name>Peter Revesz</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">27 pages, 4 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0212017v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0212017v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.8\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0212051v1</id>\n    <updated>2002-12-23T10:26:36Z</updated>\n    <published>2002-12-23T10:26:36Z</published>\n    <title>ExploitingWeb Service Semantics: Taxonomies vs. Ontologies</title>\n    <summary>  Comprehensive semantic descriptions of Web services are essential to exploit\nthem in their full potential, that is, discovering them dynamically, and\nenabling automated service negotiation, composition and monitoring. The\nsemantic mechanisms currently available in service registries which are based\non taxonomies fail to provide the means to achieve this. Although the terms\ntaxonomy and ontology are sometimes used interchangably there is a critical\ndifference. A taxonomy indicates only class/subclass relationship whereas an\nontology describes a domain completely. The essential mechanisms that ontology\nlanguages provide include their formal specification (which allows them to be\nqueried) and their ability to define properties of classes. Through properties\nvery accurate descriptions of services can be defined and services can be\nrelated to other services or resources. In this paper, we discuss the\nadvantages of describing service semantics through ontology languages and\ndescribe how to relate the semantics defined with the services advertised in\nservice registries like UDDI and ebXML.\n</summary>\n    <author>\n      <name>Asuman Dogac</name>\n    </author>\n    <author>\n      <name>Gokce Laleci</name>\n    </author>\n    <author>\n      <name>Yildiray Kabak</name>\n    </author>\n    <author>\n      <name>Ibrahim Cingil</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">7 pages</arxiv:comment>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">IEEE Data Engineering Bulletin, Vol. 25, No. 4, December 2002</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/0212051v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0212051v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"D\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0212052v1</id>\n    <updated>2002-12-25T15:15:16Z</updated>\n    <published>2002-12-25T15:15:16Z</published>\n    <title>Improving the Functionality of UDDI Registries through Web Service\n  Semantics</title>\n    <summary>  In this paper we describe a framework for exploiting the semantics of Web\nservices through UDDI registries. As a part of this framework, we extend the\nDAML-S upper ontology to describe the functionality we find essential for\ne-businesses. This functionality includes relating the services with electronic\ncatalogs, describing the complementary services and finding services according\nto the properties of products or services. Once the semantics is defined, there\nis a need for a mechanism in the service registry to relate it with the service\nadvertised. The ontology model developed is general enough to be used with any\nservice registry. However when it comes to relating the semantics with services\nadvertised, the capabilities provided by the registry effects how this is\nachieved. We demonstrate how to integrate the described service semantics to\nUDDI registries.\n</summary>\n    <author>\n      <name>Asuman Dogac</name>\n    </author>\n    <author>\n      <name>Ibrahim Cingil</name>\n    </author>\n    <author>\n      <name>Gokce Laleci</name>\n    </author>\n    <author>\n      <name>Yildiray Kabak</name>\n    </author>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">3rd VLDB Workshop on Technologies for E-Services (TES-02), Hong\n  Kong, China, August 23-24, 2002</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/0212052v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0212052v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"D\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0301009v1</id>\n    <updated>2003-01-13T05:34:39Z</updated>\n    <published>2003-01-13T05:34:39Z</published>\n    <title>A Script Language for Data Integration in Database</title>\n    <summary>  A Script Language in this paper is designed to transform the original data\ninto the target data by the computing formula. The Script Language can be\ntranslated into the corresponding SQL Language, and the computation is finally\nimplemented by the first type of dynamic SQL. The Script Language has the\noperations of insert, update, delete, union, intersect, and minus for the table\nin the database.The Script Language is edited by a text file and you can easily\nmodify the computing formula in the text file to deal with the situations when\nthe computing formula have been changed. So you only need modify the text of\nthe script language, but needn't change the programs that have complied.\n</summary>\n    <author>\n      <name>Qingguo Zheng</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">9 pages</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0301009v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0301009v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.5\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0301017v1</id>\n    <updated>2003-01-20T00:13:18Z</updated>\n    <published>2003-01-20T00:13:18Z</published>\n    <title>Completeness and Decidability Properties for Functional Dependencies in\n  XML</title>\n    <summary>  XML is of great importance in information storage and retrieval because of\nits recent emergence as a standard for data representation and interchange on\nthe Internet. However XML provides little semantic content and as a result\nseveral papers have addressed the topic of how to improve the semantic\nexpressiveness of XML. Among the most important of these approaches has been\nthat of defining integrity constraints in XML. In a companion paper we defined\nstrong functional dependencies in XML(XFDs). We also presented a set of axioms\nfor reasoning about the implication of XFDs and showed that the axiom system is\nsound for arbitrary XFDs. In this paper we prove that the axioms are also\ncomplete for unary XFDs (XFDs with a single path on the l.h.s.). The second\ncontribution of the paper is to prove that the implication problem for unary\nXFDs is decidable and to provide a linear time algorithm for it.\n</summary>\n    <author>\n      <name>Millist W. Vincent</name>\n    </author>\n    <author>\n      <name>Jixue Liu</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/cs/0301017v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0301017v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.1\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0305038v1</id>\n    <updated>2003-05-21T15:59:56Z</updated>\n    <published>2003-05-21T15:59:56Z</published>\n    <title>The Evolution of the Computerized Database</title>\n    <summary>  Databases, collections of related data, are as old as the written word. A\ndatabase can be anything from a homemaker's metal recipe file to a\nsophisticated data warehouse. Yet today, when we think of a database we\ninvariably think of computerized data and their DBMSs (database management\nsystems). How did we go from organizing our data in a simple metal filing box\nor cabinet to storing our data in a sophisticated computerized database? How\ndid the computerized database evolve?\n  This paper defines what we mean by a database. It traces the evolution of the\ndatabase, from its start as a non-computerized set of related data, to the, now\nstandard, computerized RDBMS (relational database management system). Early\ncomputerized storage methods are reviewed including both the ISAM (Indexed\nSequential Access Method) and VSAM (Virtual Storage Access Method) storage\nmethods. Early database models are explored including the network and\nhierarchical database models. Eventually, the relational, object-relational and\nobject-oriented databases models are discussed. An appendix of diagrams,\nincluding hierarchical occurrence tree, network schema, ER (entity\nrelationship) and UML (unified modeling language) diagrams, is included to\nsupport the text.\n  This paper concludes with an exploration of current and future trends in DBMS\ndevelopment. It discusses the factors affecting these trends. It delves into\nthe relationship between DBMSs and the increasingly popular object-oriented\ndevelopment methodologies. Finally, it speculates on the future of the DBMS.\n</summary>\n    <author>\n      <name>Nancy Hartline Bercich</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">13 pages, including figures and bibliography</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0305038v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0305038v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.m\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0306006v2</id>\n    <updated>2003-06-14T01:51:57Z</updated>\n    <published>2003-05-30T23:08:44Z</published>\n    <title>Experience with the Open Source based implementation for ATLAS\n  Conditions Data Management System</title>\n    <summary>  Conditions Data in high energy physics experiments is frequently seen as\nevery data needed for reconstruction besides the event data itself. This\nincludes all sorts of slowly evolving data like detector alignment, calibration\nand robustness, and data from detector control system. Also, every Conditions\nData Object is associated with a time interval of validity and a version.\nBesides that, quite often is useful to tag collections of Conditions Data\nObjects altogether. These issues have already been investigated and a data\nmodel has been proposed and used for different implementations based in\ncommercial DBMSs, both at CERN and for the BaBar experiment. The special case\nof the ATLAS complex trigger that requires online access to calibration and\nalignment data poses new challenges that have to be met using a flexible and\ncustomizable solution more in the line of Open Source components. Motivated by\nthe ATLAS challenges we have developed an alternative implementation, based in\nan Open Source RDBMS. Several issues were investigated land will be described\nin this paper:\n  -The best way to map the conditions data model into the relational database\nconcept considering what are foreseen as the most frequent queries.\n  -The clustering model best suited to address the scalability problem.\n-Extensive tests were performed and will be described.\n  The very promising results from these tests are attracting the attention from\nthe HEP community and driving further developments.\n</summary>\n    <author>\n      <name>A. Amorim</name>\n    </author>\n    <author>\n      <name>J. Lima</name>\n    </author>\n    <author>\n      <name>C. Oliveira</name>\n    </author>\n    <author>\n      <name>L. Pedro</name>\n    </author>\n    <author>\n      <name>N. Barros</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">8 pages, 4 figures, 3 tables, conference</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0306006v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0306006v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.4; H.2.2; H.3.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0306013v1</id>\n    <updated>2003-06-02T09:38:47Z</updated>\n    <published>2003-06-02T09:38:47Z</published>\n    <title>Transparent Persistence with Java Data Objects</title>\n    <summary>  Flexible and performant Persistency Service is a necessary component of any\nHEP Software Framework. The building of a modular, non-intrusive and performant\npersistency component have been shown to be very difficult task. In the past,\nit was very often necessary to sacrifice modularity to achieve acceptable\nperformance. This resulted in the strong dependency of the overall Frameworks\non their Persistency subsystems.\n  Recent development in software technology has made possible to build a\nPersistency Service which can be transparently used from other Frameworks. Such\nService doesn't force a strong architectural constraints on the overall\nFramework Architecture, while satisfying high performance requirements. Java\nData Object standard (JDO) has been already implemented for almost all major\ndatabases. It provides truly transparent persistency for any Java object (both\ninternal and external). Objects in other languages can be handled via\ntransparent proxies. Being only a thin layer on top of a used database, JDO\ndoesn't introduce any significant performance degradation. Also Aspect-Oriented\nProgramming (AOP) makes possible to treat persistency as an orthogonal Aspect\nof the Application Framework, without polluting it with persistence-specific\nconcepts.\n  All these techniques have been developed primarily (or only) for the Java\nenvironment. It is, however, possible to interface them transparently to\nFrameworks built in other languages, like for example C++.\n  Fully functional prototypes of flexible and non-intrusive persistency modules\nhave been build for several other packages, as for example FreeHEP AIDA and LCG\nPool AttributeSet (package Indicium).\n</summary>\n    <author>\n      <name>Julius Hrivnac</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Talk from the 2003 Computing in High Energy and Nuclear Physics\n  (CHEP03), La Jolla, Ca, USA, March 2003. PSN TUKT005</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0306013v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0306013v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0306019v1</id>\n    <updated>2003-06-04T17:38:23Z</updated>\n    <published>2003-06-04T17:38:23Z</published>\n    <title>Relational databases for data management in PHENIX</title>\n    <summary>  PHENIX is one of the two large experiments at the Relativistic Heavy Ion\nCollider (RHIC) at Brookhaven National Laboratory (BNL) and archives roughly\n100TB of experimental data per year. In addition, large volumes of simulated\ndata are produced at multiple off-site computing centers. For any file catalog\nto play a central role in data management it has to face problems associated\nwith the need for distributed access and updates. To be used effectively by the\nhundreds of PHENIX collaborators in 12 countries the catalog must satisfy the\nfollowing requirements: 1) contain up-to-date data, 2) provide fast and\nreliable access to the data, 3) have write permissions for the sites that store\nportions of data. We present an analysis of several available Relational\nDatabase Management Systems (RDBMS) to support a catalog meeting the above\nrequirements and discuss the PHENIX experience with building and using the\ndistributed file catalog.\n</summary>\n    <author>\n      <name>I. Sourikova</name>\n    </author>\n    <author>\n      <name>D. Morrison</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Talk from the 2003 Computing in High Energy and Nuclear Physics\n  (CHEP03), La Jolla, Ca, USA, March 2003, 4 pages, LaTeX, 4 eps figures. PSN\n  TUKT003</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0306019v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0306019v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.4\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0306020v2</id>\n    <updated>2003-06-04T20:12:08Z</updated>\n    <published>2003-06-04T19:22:52Z</published>\n    <title>On the Verge of One Petabyte - the Story Behind the BaBar Database\n  System</title>\n    <summary>  The BaBar database has pioneered the use of a commercial ODBMS within the HEP\ncommunity. The unique object-oriented architecture of Objectivity/DB has made\nit possible to manage over 700 terabytes of production data generated since\nMay'99, making the BaBar database the world's largest known database. The\nongoing development includes new features, addressing the ever-increasing\nluminosity of the detector as well as other changing physics requirements.\nSignificant efforts are focused on reducing space requirements and operational\ncosts. The paper discusses our experience with developing a large scale\ndatabase system, emphasizing universal aspects which may be applied to any\nlarge scale system, independently of underlying technology used.\n</summary>\n    <author>\n      <name>Adeyemi Adesanya</name>\n    </author>\n    <author>\n      <name>Tofigh Azemoon</name>\n    </author>\n    <author>\n      <name>Jacek Becla</name>\n    </author>\n    <author>\n      <name>Andrew Hanushevsky</name>\n    </author>\n    <author>\n      <name>Adil Hasan</name>\n    </author>\n    <author>\n      <name>Wilko Kroeger</name>\n    </author>\n    <author>\n      <name>Artem Trunov</name>\n    </author>\n    <author>\n      <name>Daniel Wang</name>\n    </author>\n    <author>\n      <name>Igor Gaponenko</name>\n    </author>\n    <author>\n      <name>Simon Patton</name>\n    </author>\n    <author>\n      <name>David Quarrie</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Talk from the 2003 Computing in High Energy and Nuclear Physics\n  (CHEP03), La Jolla, Ca, USA, March 2003, 6 pages. PSN MOKT010</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0306020v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0306020v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"C.2.4; H.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0306034v1</id>\n    <updated>2003-06-07T15:09:16Z</updated>\n    <published>2003-06-07T15:09:16Z</published>\n    <title>A ROOT/IO Based Software Framework for CMS</title>\n    <summary>  The implementation of persistency in the Compact Muon Solenoid (CMS) Software\nFramework uses the core I/O functionality of ROOT. We will discuss the current\nROOT/IO implementation, its evolution from the prior Objectivity/DB\nimplementation, and the plans and ongoing work for the conversion to \"POOL\",\nprovided by the LHC Computing Grid (LCG) persistency project.\n</summary>\n    <author>\n      <name>William Tanenbaum</name>\n    </author>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">ECONFC0303241:TUKT010,2003</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/0306034v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0306034v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"E.1\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0306056v1</id>\n    <updated>2003-06-12T17:24:16Z</updated>\n    <published>2003-06-12T17:24:16Z</published>\n    <title>Twelve Ways to Build CMS Crossings from ROOT Files</title>\n    <summary>  The simulation of CMS raw data requires the random selection of one hundred\nand fifty pileup events from a very large set of files, to be superimposed in\nmemory to the signal event. The use of ROOT I/O for that purpose is quite\nunusual: the events are not read sequentially but pseudo-randomly, they are not\nprocessed one by one in memory but by bunches, and they do not contain orthodox\nROOT objects but many foreign objects and templates. In this context, we have\ncompared the performance of ROOT containers versus the STL vectors, and the use\nof trees versus a direct storage of containers. The strategy with best\nperformances is by far the one using clones within trees, but it stays hard to\ntune and very dependant on the exact use-case. The use of STL vectors could\nbring more easily similar performances in a future ROOT release.\n</summary>\n    <author>\n      <name>D. Chamont</name>\n    </author>\n    <author>\n      <name>C. Charlot</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Talk from the 2003 Computing in High Energy and Nuclear Physics\n  (CHEP03), La Jolla, Ca, USA, March 2003, 8 pages, LaTeX, 1 eps figures. PSN\n  TUKT004</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0306056v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0306056v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.4\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0306065v1</id>\n    <updated>2003-06-13T16:21:53Z</updated>\n    <published>2003-06-13T16:21:53Z</published>\n    <title>POOL File Catalog, Collection and Metadata Components</title>\n    <summary>  The POOL project is the common persistency framework for the LHC experiments\nto store petabytes of experiment data and metadata in a distributed and grid\nenabled way. POOL is a hybrid event store consisting of a data streaming layer\nand a relational layer. This paper describes the design of file catalog,\ncollection and metadata components which are not part of the data streaming\nlayer of POOL and outlines how POOL aims to provide transparent and efficient\ndata access for a wide range of environments and use cases - ranging from a\nlarge production site down to a single disconnected laptops. The file catalog\nis the central POOL component translating logical data references to physical\ndata files in a grid environment. POOL collections with their associated\nmetadata provide an abstract way of accessing experiment data via their logical\ngrouping into sets of related data objects.\n</summary>\n    <author>\n      <name>C. Cioffi</name>\n    </author>\n    <author>\n      <name>S. Eckmann</name>\n    </author>\n    <author>\n      <name>M. Girone</name>\n    </author>\n    <author>\n      <name>J. Hrivnac</name>\n    </author>\n    <author>\n      <name>D. Malon</name>\n    </author>\n    <author>\n      <name>H. Schmuecker</name>\n    </author>\n    <author>\n      <name>A. Vaniachine</name>\n    </author>\n    <author>\n      <name>J. Wojcieszuk</name>\n    </author>\n    <author>\n      <name>Z. Xie</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Talk from the 2003 Computing in High Energy and Nuclear Physics\n  (CHEP03), La Jolla, Ca, USA, March 2003, 4 pages, 1 eps figure, PSN MOKT009</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0306065v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0306065v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.4\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0306066v1</id>\n    <updated>2003-06-13T14:33:53Z</updated>\n    <published>2003-06-13T14:33:53Z</published>\n    <title>The COMPASS Event Store in 2002</title>\n    <summary>  COMPASS, the fixed-target experiment at CERN studying the structure of the\nnucleon and spectroscopy, collected over 260 TB during summer 2002 run. All\nthese data, together with reconstructed events information, were put from the\nbeginning in a database infrastructure based on Objectivity/DB and on the\nhierarchical storage manager CASTOR. The experience in the usage of the\ndatabase is reviewed and the evolution of the system outlined.\n</summary>\n    <author>\n      <name>Venicio Duic</name>\n    </author>\n    <author>\n      <name>Massimo Lamanna</name>\n    </author>\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1109/TNS.2004.832645</arxiv:doi>\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1109/TNS.2004.832645\" rel=\"related\"/>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Talk from the 2003 conference: \"Computing in High Energy and Nuclear\n  Physics\" (CHEP03), La Jolla, Ca, USA, March 2003, 6 pages. PSN MOKT011</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0306066v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0306066v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2; H.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0306077v1</id>\n    <updated>2003-06-13T22:10:36Z</updated>\n    <published>2003-06-13T22:10:36Z</published>\n    <title>The TESLA Requirements Database</title>\n    <summary>  In preparation for the planned linear collider TESLA, DESY is designing the\nrequired buildings and facilities. The accelerator and infrastructure\ncomponents have to be allocated to buildings, and their required areas for\ninstallation, operation and maintenance have to be determined.\nInterdisciplinary working groups specify the project from different viewpoints\nand need to develop a common vision as a precondition for an optimal solution.\nA commercial requirements database is used as a collaborative tool, enabling\nconcurrent requirements specification by independent working groups. The\nrequirements database ensures long term storage and availability of the\nemerging knowledge, and it offers a central platform for communication which is\navailable for all project members. It is successfully operating since summer\n2002 and has since then become an important tool for the design team.\n</summary>\n    <author>\n      <name>Lars Hagge</name>\n    </author>\n    <author>\n      <name>Jens Kreutzkamp</name>\n    </author>\n    <author>\n      <name>Kathrin Lappe</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Contribution to CHEP2003 conference</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0306077v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0306077v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"D.2.1;H.4.0;K.6.1\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0306079v1</id>\n    <updated>2003-06-13T23:04:10Z</updated>\n    <published>2003-06-13T23:04:10Z</published>\n    <title>Integrated Information Management for TESLA</title>\n    <summary>  Next-generation projects in High Energy Physics will reach again a new\ndimension of complexity. Information management has to ensure an efficient and\neconomic information flow within the collaborations, offering world-wide\nup-to-date information access to the collaborators as one condition for\nsuccessful projects. DESY introduces several information systems in preparation\nfor the planned linear collider TESLA: a Requirements Management System (RMS)\nis in production for the TESLA planning group, a Product Data Management System\n(PDMS) is in production since the beginning of 2002 and is supporting the\ncavity preparation and the general engineering of accelerator components. A\npilot Asset Management System (AMS) is in production for supporting the\nmanagement and maintenance of the technical infrastructure, and a Facility\nManagement System (FMS) with a Geographic Information System (GIS) is currently\nbeing introduced to support civil engineering. Efforts have been started to\nintegrate the systems with the goal that users can retrieve information through\na single point of access. The paper gives an introduction to information\nmanagement and the activities at DESY.\n</summary>\n    <author>\n      <name>Jochen Buerger</name>\n    </author>\n    <author>\n      <name>Lars Hagge</name>\n    </author>\n    <author>\n      <name>Jens Kreutzkamp</name>\n    </author>\n    <author>\n      <name>Kathrin Lappe</name>\n    </author>\n    <author>\n      <name>Andrea Robben</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Contribution to CHEP2003 conference</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0306079v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0306079v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.4.0;K.6.1\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0306081v1</id>\n    <updated>2003-06-14T00:42:30Z</updated>\n    <published>2003-06-14T00:42:30Z</published>\n    <title>An on-line Integrated Bookkeeping: electronic run log book and Meta-Data\n  Repository for ATLAS</title>\n    <summary>  In the context of the ATLAS experiment there is growing evidence of the\nimportance of different kinds of Meta-data including all the important details\nof the detector and data acquisition that are vital for the analysis of the\nacquired data. The Online BookKeeper (OBK) is a component of ATLAS online\nsoftware that stores all information collected while running the experiment,\nincluding the Meta-data associated with the event acquisition, triggering and\nstorage. The facilities for acquisition of control data within the on-line\nsoftware framework, together with a full functional Web interface, make the OBK\na powerful tool containing all information needed for event analysis, including\nan electronic log book.\n  In this paper we explain how OBK plays a role as one of the main collectors\nand managers of Meta-data produced on-line, and we'll also focus on the Web\nfacilities already available. The usage of the web interface as an electronic\nrun logbook is also explained, together with the future extensions.\n  We describe the technology used in OBK development and how we arrived at the\npresent level explaining the previous experience with various DBMS\ntechnologies. The extensive performance evaluations that have been performed\nand the usage in the production environment of the ATLAS test beams are also\nanalysed.\n</summary>\n    <author>\n      <name>M. Barczyc</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">CERN</arxiv:affiliation>\n    </author>\n    <author>\n      <name>D. Burckhart-Chromek</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">CERN</arxiv:affiliation>\n    </author>\n    <author>\n      <name>M. Caprini</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">CERN</arxiv:affiliation>\n    </author>\n    <author>\n      <name>J. Da Silva Conceicao</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">CERN</arxiv:affiliation>\n    </author>\n    <author>\n      <name>M. Dobson</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">CERN</arxiv:affiliation>\n    </author>\n    <author>\n      <name>J. Flammer</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">CERN</arxiv:affiliation>\n    </author>\n    <author>\n      <name>R. Jones</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">CERN</arxiv:affiliation>\n    </author>\n    <author>\n      <name>A. Kazarov</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">CERN</arxiv:affiliation>\n    </author>\n    <author>\n      <name>S. Kolos</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">CERN</arxiv:affiliation>\n    </author>\n    <author>\n      <name>D. Liko</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">CERN</arxiv:affiliation>\n    </author>\n    <author>\n      <name>L. Mapelli</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">CERN</arxiv:affiliation>\n    </author>\n    <author>\n      <name>I. Soloviev</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">CERN</arxiv:affiliation>\n    </author>\n    <author>\n      <name>R. Hart NIKHEF</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Amsterdam, Netherlands</arxiv:affiliation>\n    </author>\n    <author>\n      <name>A. Amorim</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">CFNUL/FCUL, Portugal</arxiv:affiliation>\n    </author>\n    <author>\n      <name>D. Klose</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">CFNUL/FCUL, Portugal</arxiv:affiliation>\n    </author>\n    <author>\n      <name>J. Lima</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">CFNUL/FCUL, Portugal</arxiv:affiliation>\n    </author>\n    <author>\n      <name>L. Lucio</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">CFNUL/FCUL, Portugal</arxiv:affiliation>\n    </author>\n    <author>\n      <name>L. Pedro</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">CFNUL/FCUL, Portugal</arxiv:affiliation>\n    </author>\n    <author>\n      <name>H. Wolters</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">UCP Figueira da Foz, Portugal</arxiv:affiliation>\n    </author>\n    <author>\n      <name>E. Badescu NIPNE</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Bucharest, Romania</arxiv:affiliation>\n    </author>\n    <author>\n      <name>I. Alexandrov</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Dubna, Russian Federation</arxiv:affiliation>\n    </author>\n    <author>\n      <name>V. Kotov</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Dubna, Russian Federation</arxiv:affiliation>\n    </author>\n    <author>\n      <name>M. Mineev JINR</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Dubna, Russian Federation</arxiv:affiliation>\n    </author>\n    <author>\n      <name>Yu. Ryabov PNPI</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Gatchina, Russian Federation</arxiv:affiliation>\n    </author>\n    <link href=\"http://arxiv.org/abs/cs/0306081v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0306081v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.4;H.2.8\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0307015v2</id>\n    <updated>2006-06-10T15:18:44Z</updated>\n    <published>2003-07-07T14:07:59Z</published>\n    <title>Architecture of an Open-Sourced, Extensible Data Warehouse Builder:\n  InterBase 6 Data Warehouse Builder (IB-DWB)</title>\n    <summary>  We report the development of an open-sourced data warehouse builder,\nInterBase Data Warehouse Builder (IB-DWB), based on Borland InterBase 6 Open\nEdition Database Server. InterBase 6 is used for its low maintenance and small\nfootprint. IB-DWB is designed modularly and consists of 5 main components, Data\nPlug Platform, Discoverer Platform, Multi-Dimensional Cube Builder, and Query\nSupporter, bounded together by a Kernel. It is also an extensible system, made\npossible by the Data Plug Platform and the Discoverer Platform. Currently,\nextensions are only possible via dynamic linked-libraries (DLLs).\nMulti-Dimensional Cube Builder represents a basal mean of data aggregation. The\narchitectural philosophy of IB-DWB centers around providing a base platform\nthat is extensible, which is functionally supported by expansion modules.\nIB-DWB is currently being hosted by sourceforge.net (Project Unix Name:\nib-dwb), licensed under GNU General Public License, Version 2.\n</summary>\n    <author>\n      <name>Maurice HT Ling</name>\n    </author>\n    <author>\n      <name>Chi Wai So</name>\n    </author>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Ling, Maurice HT and So, Chi Wai. 2003. Proceedings of the First\n  Australian Undergraduate Students' Computing Conference. (pp. 40-45)</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/cs/0307015v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0307015v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.8; H.4.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0307073v1</id>\n    <updated>2003-07-31T11:18:51Z</updated>\n    <published>2003-07-31T11:18:51Z</published>\n    <title>Search and Navigation in Relational Databases</title>\n    <summary>  We present a new application for keyword search within relational databases,\nwhich uses a novel algorithm to solve the join discovery problem by finding\nMemex-like trails through the graph of foreign key dependencies. It differs\nfrom previous efforts in the algorithms used, in the presentation mechanism and\nin the use of primary-key only database queries at query-time to maintain a\nfast response for users. We present examples using the DBLP data set.\n</summary>\n    <author>\n      <name>Richard Wheeldon</name>\n    </author>\n    <author>\n      <name>Mark Levene</name>\n    </author>\n    <author>\n      <name>Kevin Keenoy</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">12 pages, 7 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0307073v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0307073v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.3;H.4;H.5\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0309011v1</id>\n    <updated>2003-09-08T19:57:46Z</updated>\n    <published>2003-09-08T19:57:46Z</published>\n    <title>Indexing of Tables Referencing Complex Structures</title>\n    <summary>  We introduce indexing of tables referencing complex structures such as\ndigraphs and spatial objects, appearing in genetics and other data intensive\nanalysis. The indexing is achieved by extracting dimension schemas from the\nreferenced structures. The schemas and their dimensionality are determined by\nproper coloring algorithms and the duality between all such schemas and all\nsuch possible proper colorings is established. This duality, in turn, provides\nus with an extensive library of solutions when addressing indexing questions.\nIt is illustrated how to use the schemas, in connection with additional\nrelational database technologies, to optimize queries conditioned on the\nstructural information being referenced. Comparisons using bitmap indexing in\nthe Oracle 9.2i database, on the one hand, and multidimensional clustering in\nDB2 8.1.2, on the other hand, are used to illustrate the applicability of the\nindexing to different technology settings. Finally, we illustrate how the\nindexing can be used to extract low dimensional schemas from a binary interval\ntree in order to resolve efficiently interval and stabbing queries.\n</summary>\n    <author>\n      <name>Agust S. Egilsson</name>\n    </author>\n    <author>\n      <name>Hakon Gudbjartsson</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">12 pages</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0309011v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0309011v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.3.1;H.2.8;J.3\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0310006v1</id>\n    <updated>2003-10-06T05:42:49Z</updated>\n    <published>2003-10-06T05:42:49Z</published>\n    <title>The Lowell Database Research Self Assessment</title>\n    <summary>  A group of senior database researchers gathers every few years to assess the\nstate of database research and to point out problem areas that deserve\nadditional focus. This report summarizes the discussion and conclusions of the\nsixth ad-hoc meeting held May 4-6, 2003 in Lowell, Mass. It observes that\ninformation management continues to be a critical component of most complex\nsoftware systems. It recommends that database researchers increase focus on:\nintegration of text, data, code, and streams; fusion of information from\nheterogeneous data sources; reasoning about uncertain data; unsupervised data\nmining for interesting correlations; information privacy; and self-adaptation\nand repair.\n</summary>\n    <author>\n      <name>Serge Abiteboul</name>\n    </author>\n    <author>\n      <name>Rakesh Agrawal</name>\n    </author>\n    <author>\n      <name>Phil Bernstein</name>\n    </author>\n    <author>\n      <name>Mike Carey</name>\n    </author>\n    <author>\n      <name>Stefano Ceri</name>\n    </author>\n    <author>\n      <name>Bruce Croft</name>\n    </author>\n    <author>\n      <name>David DeWitt</name>\n    </author>\n    <author>\n      <name>Mike Franklin</name>\n    </author>\n    <author>\n      <name>Hector Garcia Molina</name>\n    </author>\n    <author>\n      <name>Dieter Gawlick</name>\n    </author>\n    <author>\n      <name>Jim Gray</name>\n    </author>\n    <author>\n      <name>Laura Haas</name>\n    </author>\n    <author>\n      <name>Alon Halevy</name>\n    </author>\n    <author>\n      <name>Joe Hellerstein</name>\n    </author>\n    <author>\n      <name>Yannis Ioannidis</name>\n    </author>\n    <author>\n      <name>Martin Kersten</name>\n    </author>\n    <author>\n      <name>Michael Pazzani</name>\n    </author>\n    <author>\n      <name>Mike Lesk</name>\n    </author>\n    <author>\n      <name>David Maier</name>\n    </author>\n    <author>\n      <name>Jeff Naughton</name>\n    </author>\n    <author>\n      <name>Hans Schek</name>\n    </author>\n    <author>\n      <name>Timos Sellis</name>\n    </author>\n    <author>\n      <name>Avi Silberschatz</name>\n    </author>\n    <author>\n      <name>Mike Stonebraker</name>\n    </author>\n    <author>\n      <name>Rick Snodgrass</name>\n    </author>\n    <author>\n      <name>Jeff Ullman</name>\n    </author>\n    <author>\n      <name>Gerhard Weikum</name>\n    </author>\n    <author>\n      <name>Jennifer Widom</name>\n    </author>\n    <author>\n      <name>Stan Zdonik</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Details of this workshop (presentations and notes) are at\n  http://research.microsoft.com/~gray/lowell/</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0310006v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0310006v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H;H.2; H.3; H.4; H.5\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0310012v1</id>\n    <updated>2003-10-08T00:18:31Z</updated>\n    <published>2003-10-08T00:18:31Z</published>\n    <title>A Formal Comparison of Visual Web Wrapper Generators</title>\n    <summary>  We study the core fragment of the Elog wrapping language used in the Lixto\nsystem (a visual wrapper generator) and formally compare Elog to other wrapping\nlanguages proposed in the literature.\n</summary>\n    <author>\n      <name>Georg Gottlob</name>\n    </author>\n    <author>\n      <name>Christoph Koch</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">12 pages, 0 figures, second part of long version of PODS 2002 paper\n  \"Monadic Datalog and the Expressive Power of Languages for Web Information\n  Extraction\". First part accepted for JACM</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0310012v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0310012v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"F.1.1, F.4.1, F.4.3, H.2.3, I.7.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/cs/0310028v1</id>\n    <updated>2003-10-15T16:07:56Z</updated>\n    <published>2003-10-15T16:07:56Z</published>\n    <title>Providing Diversity in K-Nearest Neighbor Query Results</title>\n    <summary>  Given a point query Q in multi-dimensional space, K-Nearest Neighbor (KNN)\nqueries return the K closest answers according to given distance metric in the\ndatabase with respect to Q. In this scenario, it is possible that a majority of\nthe answers may be very similar to some other, especially when the data has\nclusters. For a variety of applications, such homogeneous result sets may not\nadd value to the user. In this paper, we consider the problem of providing\ndiversity in the results of KNN queries, that is, to produce the closest result\nset such that each answer is sufficiently different from the rest. We first\npropose a user-tunable definition of diversity, and then present an algorithm,\ncalled MOTLEY, for producing a diverse result set as per this definition.\nThrough a detailed experimental evaluation on real and synthetic data, we show\nthat MOTLEY can produce diverse result sets by reading only a small fraction of\nthe tuples in the database. Further, it imposes no additional overhead on the\nevaluation of traditional KNN queries, thereby providing a seamless interface\nbetween diversity and distance.\n</summary>\n    <author>\n      <name>Anoop Jain</name>\n    </author>\n    <author>\n      <name>Parag Sarda</name>\n    </author>\n    <author>\n      <name>Jayant R. Haritsa</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">20 pages, 11 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/cs/0310028v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cs/0310028v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"H.2.4\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n</feed>\n"